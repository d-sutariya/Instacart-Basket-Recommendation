{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:00.402229Z","iopub.status.busy":"2024-11-03T05:54:00.401773Z","iopub.status.idle":"2024-11-03T05:54:00.408593Z","shell.execute_reply":"2024-11-03T05:54:00.407102Z","shell.execute_reply.started":"2024-11-03T05:54:00.402182Z"},"trusted":true},"outputs":[],"source":["# from instacart_feature_transformation_script import FeatureGenerator,generate_test_set_features"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:00.411413Z","iopub.status.busy":"2024-11-03T05:54:00.410884Z","iopub.status.idle":"2024-11-03T05:54:00.600473Z","shell.execute_reply":"2024-11-03T05:54:00.599265Z","shell.execute_reply.started":"2024-11-03T05:54:00.411362Z"},"trusted":true},"outputs":[],"source":["\n","import time\n","import pyspark\n","import numpy as np\n","from pyspark.sql import SparkSession, Window\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import LongType, DoubleType , StringType\n","\n","\n","# How often user has reordered\n","class FeatureGenerator:\n","    \n","    def __init__(self,prior_product_orders,prior_orders_df,products_df):\n","        \n","        self.prior_product_orders = prior_product_orders\n","        self.prior_orders_df = prior_orders_df\n","        self.products_df= products_df\n","\n","\n","    def generate_user_related_features(self):\n","        \n","        df_with_num_of_reord = (\n","            self.prior_product_orders.select(\"reordered\", \"order_id\")\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), how=\"left\", on=\"order_id\")\n","            .select(\"user_id\", \"reordered\")\n","            .groupBy(\"user_id\")\n","            .agg(F.count(F.col(\"reordered\")).alias(\"frequency_of_reorder\"))\n","        )\n","        \n","   \n","        # Time of the day user visits\n","        df_with_time_of_day_usr_visits = (\n","            self.prior_orders_df.select(\"user_id\", \"order_hour_of_day\", \"order_id\")\n","            .groupBy(\"user_id\", \"order_hour_of_day\")\n","            .agg(F.count(\"order_id\").alias(\"frequency\"))\n","            .groupBy(\"user_id\")\n","            .agg(F.max(\"frequency\").alias(\"maximum_frquency\"))\n","        )\n","        \n","        # Does the user order Asian, gluten-free, or organic items\n","        df_with_does_usr_asian_gluten_orga_items_ord = (\n","            self.prior_product_orders.select(\"order_id\", \"product_id\")\n","            .join(self.products_df.select(\"product_id\", \"product_name\"), on=\"product_id\", how='left')\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), on=\"order_id\", how='left')\n","            .groupBy(\"user_id\", \"order_id\")\n","            .agg(F.collect_list(\"product_name\").alias(\"list_of_products\"))\n","            .withColumn(\"normalized_list\", F.expr(\"transform(list_of_products, x -> lower(x))\"))\n","            .withColumn(\"contains_or_not\", \n","                        F.expr(\"exists(normalized_list,x -> x like '%organic%')\") |\n","                        F.expr(\"exists(normalized_list, x -> x like '%asian%')\") |\n","                        F.expr(\"exists(normalized_list, x -> x like '%gluten free%')\")\n","            )\n","            .groupBy(\"user_id\")\n","            .agg(\n","                F.sum(F.col(\"contains_or_not\").cast(\"int\")).alias(\"count_of_asian_org_items\"),\n","                F.mean(F.col(\"contains_or_not\").cast(\"int\")).alias(\"mean_of_asian_org_items\")\n","            )\n","        )\n","        \n","        # Feature based on order size\n","        df_with_fets_of_ord_size = (\n","            self.prior_product_orders.select(\"product_id\", \"order_id\")\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), on=\"order_id\", how=\"left\")\n","            .groupBy(\"user_id\", 'order_id')\n","            .agg(F.count(F.col(\"product_id\")).alias(\"count_of_product\"))\n","            .groupBy(\"user_id\")\n","            .agg(F.max(F.col(\"count_of_product\")).alias(\"max_count_of_products\"),\n","                 F.min(F.col(\"count_of_product\")).alias(\"min_count_of_products\"),\n","                 F.mean(F.col(\"count_of_product\")).alias(\"mean_count_of_products\"))\n","        )\n","        \n","        # How many of the userâ€™s orders contained no previously purchased items\n","        df_with_freq_ord_that_hasnt_prev_purch_items = (\n","            self.prior_product_orders.select(\"order_id\", \"reordered\")\n","            .join(self.prior_orders_df.select(\"order_id\", \"user_id\"), on='order_id', how='left')\n","            .groupBy(\"user_id\", \"order_id\")\n","            .agg(F.collect_list(F.col(\"reordered\")).alias(\"reordered_array\"))\n","            .withColumn(\"doesnt_contains_reordered\", F.when(F.array_contains(\"reordered_array\", 1), 0).otherwise(1))\n","            .groupBy(\"user_id\")\n","            .agg(\n","                F.sum(\"doesnt_contains_reordered\").alias(\"count_ord_no_prev_purchased_items\"),\n","                F.mean(\"doesnt_contains_reordered\").alias(\"mean_ord_no_prev_purchased_items\")    \n","            )\n","        )\n","\n","        result_df = (\n","            df_with_num_of_reord\n","            .join(df_with_does_usr_asian_gluten_orga_items_ord, on=\"user_id\", how='left')\n","            .join(df_with_fets_of_ord_size, on=\"user_id\", how='left')\n","            .join(df_with_freq_ord_that_hasnt_prev_purch_items, on=\"user_id\", how='left')\n","        )\n","        long_cols = [field.name for field in result_df.schema.fields if isinstance(field.dataType, LongType)]\n","        columns_to_cast = {col_name: F.col(col_name).cast(DoubleType()) for col_name in long_cols}\n","        result_df = result_df.withColumns(columns_to_cast)\n","        return result_df\n","        \n","    def generate_product_related_features(self):\n","                \n","        # How often the item has been purchased\n","        df_with_freq_purch = (\n","            self.prior_product_orders.select(\"product_id\", \"order_id\")\n","            .groupBy(\"product_id\")\n","            .agg(F.count(F.col(\"order_id\")).alias(\"product_count\"))\n","        )\n","        \n","        # Position of product\n","        df_with_avg_position_of_prod = (\n","            self.prior_product_orders.select(\"product_id\", \"add_to_cart_order\")\n","            .groupBy(\"product_id\")\n","            .agg(F.mean(F.col(\"add_to_cart_order\")).alias(\"product_mean_of_position\"))\n","        )\n","        \n","        # How many users buy it as a \"one-shot\" item\n","        df_with_freq_one_shot_ord_prods = (\n","            self.prior_product_orders.select(\"order_id\", \"product_id\")\n","            .groupBy(\"order_id\")\n","            .agg(F.collect_list(\"product_id\").alias(\"list_of_products\"))\n","            .withColumn(\"is_one_shot_order\", F.when(F.size(F.col(\"list_of_products\")) == 1, 1).otherwise(0))\n","            .withColumn(\"product_id\", F.explode(F.col(\"list_of_products\")))\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), on=\"order_id\", how='left')\n","            .groupBy(\"product_id\", \"user_id\")\n","            .agg(F.collect_list(F.col(\"is_one_shot_order\")).alias(\"is_one_shot_order_list\"))\n","            .withColumn(\"has_user_purchased_one_shot\", F.when(F.array_contains(\"is_one_shot_order_list\", 1), 1).otherwise(0))\n","            .groupBy(\"product_id\")\n","            .agg(F.sum(F.col(\"has_user_purchased_one_shot\")).alias(\"number_of_user_purchased_item\"))\n","        )\n","        \n","        # Statistics on the number of items that co-occur with this item\n","        df_with_freq_co_ocrd = (\n","            self.prior_product_orders\n","            .select(\"product_id\", \"order_id\")\n","            .alias(\"df1\")\n","            .join(self.prior_product_orders.select(\"product_id\", \"order_id\").withColumnRenamed(\"product_id\", \"product_id_1\").alias(\"df2\"),\n","                  (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n","                  \"left\")\n","            .groupBy(\"df1.product_id\")\n","            .agg(F.count(F.col(\"df2.product_id_1\")).alias(\"number_of_product_co_occurred\"))\n","        )\n","        \n","        # Average number of items that co-occur with this item in a single order\n","        df_with_avg_num_item_co_ocrd_in_ord = (\n","            self.prior_product_orders.select(\"product_id\", \"order_id\").alias(\"ppo1\")\n","            .join(self.prior_product_orders.select(\"product_id\", \"order_id\").alias(\"ppo2\"),\n","                  (F.col(\"ppo1.order_id\") == F.col(\"ppo2.order_id\")) & (F.col(\"ppo1.product_id\") != F.col(\"ppo2.product_id\")),\n","                  how='left')\n","            .groupBy(\"ppo1.product_id\", \"ppo1.order_id\")\n","            .agg(F.count(F.col(\"ppo2.product_id\")).alias(\"count_of_co_ocuured_product_per_order\"))\n","            .groupBy(\"ppo1.product_id\")\n","            .agg(F.mean(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"mean_of_co_ocuured_product_per_order\"),\n","                 F.min(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"min_of_co_ocuured_product_per_order\"),\n","                 F.max(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"max_of_co_ocuured_product_per_order\"))\n","        )\n","        \n","        # Stats on the order streak\n","        df_with_flag = (\n","            self.prior_product_orders.select(\"product_id\", \"order_id\")\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_number\", \"order_id\"), how='left', on='order_id')\n","            .withColumn(\"next_order_number\", F.lead(F.col(\"order_number\"), 1).over(Window.partitionBy(\"user_id\", \"product_id\").orderBy(\"order_number\")))\n","            .withColumn(\"is_streak_continued_flag\", F.when(F.col(\"next_order_number\") - F.col(\"order_number\") == 1, 1).otherwise(0))\n","        )\n","        \n","        w1 = Window.partitionBy(\"user_id\", \"product_id\").orderBy(\"order_number\")\n","        w2 = Window.partitionBy(\"user_id\", \"product_id\", \"is_streak_continued_flag\").orderBy(\"order_number\")\n","        \n","        df_with_streak_length = (\n","            df_with_flag.withColumn(\"grp\", F.row_number().over(w1) - F.row_number().over(w2))\n","            .groupBy(\"user_id\", \"product_id\", \"grp\")\n","            .agg(F.count(\"order_number\").alias(\"length_of_streaks\"))\n","        )\n","        \n","        df_with_stats_of_streaks = (\n","            df_with_streak_length.select(\"product_id\", \"length_of_streaks\", \"grp\")\n","            .groupBy(\"product_id\")\n","            .agg(F.count('grp').alias(\"Total_streak_of_this_product\"),\n","                 F.mean(\"length_of_streaks\").alias(\"mean_of_streaks_of_this_product\"),\n","                 F.min(\"length_of_streaks\").alias(\"min_of_streaks_of_this_product\"),\n","                 F.max(\"length_of_streaks\").alias(\"max_of_streaks_of_this_product\"))\n","        )\n","        \n","        # Probability of being reordered within N orders\n","        df_with_prob_greater_5 = (\n","            df_with_streak_length.withColumn(\"is_streak_length_greater_than_5\", F.when(F.col(\"length_of_streaks\") >= 5, 1).otherwise(0))\n","            .groupBy(\"product_id\")\n","            .agg(F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n","                 F.sum(\"is_streak_length_greater_than_5\").alias(\"total_streaks_greater_than_5\"))\n","            .withColumn(\"prob_of_reordered_5\", F.col(\"total_streaks_greater_than_5\") / F.col(\"total_streaks\"))\n","            .select(\"product_id\", \"prob_of_reordered_5\")\n","        )\n","        \n","        df_with_prob_greater_2 = (\n","            df_with_streak_length.withColumn(\"is_streak_length_greater_than_2\", F.when(F.col(\"length_of_streaks\") >= 2, 1).otherwise(0))\n","            .groupBy(\"product_id\")\n","            .agg(F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n","                 F.sum(\"is_streak_length_greater_than_2\").alias(\"total_streaks_greater_than_2\"))\n","            .withColumn(\"prob_of_reordered_2\", F.col(\"total_streaks_greater_than_2\") / F.col(\"total_streaks\"))\n","            .select(\"product_id\", \"prob_of_reordered_2\")\n","        )\n","        \n","        df_with_prob_greater_3 = (\n","            df_with_streak_length.withColumn(\"is_streak_length_greater_than_3\", F.when(F.col(\"length_of_streaks\") >= 3, 1).otherwise(0))\n","            .groupBy(\"product_id\")\n","            .agg(F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n","                 F.sum(\"is_streak_length_greater_than_3\").alias(\"total_streaks_greater_than_3\"))\n","            .withColumn(\"prob_of_reordered_3\", F.col(\"total_streaks_greater_than_3\") / F.col(\"total_streaks\"))\n","            .select(\"product_id\", \"prob_of_reordered_3\")\n","        )\n","        \n","        # Distribution of the day of week it is ordered\n","        pivoted_prior_orders_df = (\n","            self.prior_orders_df.select(\"order_id\", \"order_dow\")\n","            .groupBy(\"order_id\")\n","            .pivot(\"order_dow\")\n","            .agg(F.lit(1)).na.fill(0)\n","        )\n","        \n","        new_column_names = [\n","            f\"dow_{col_name.split('.')[0]}\" if col_name != \"order_id\" else col_name \n","            for col_name in pivoted_prior_orders_df.columns\n","        ]\n","        # Apply the renamed columns\n","        pivoted_prior_orders_df = pivoted_prior_orders_df.toDF(*new_column_names)\n","        \n","        df_with_count_of_dow_p_prod = (\n","            self.prior_product_orders.select(\"order_id\", \"product_id\")\n","            .join(pivoted_prior_orders_df, on=\"order_id\", how='left')\n","            .groupBy(\"product_id\")\n","            .agg(F.sum(\"dow_0\").alias(\"distrib_count_of_dow_0_p_prod\"),\n","                 F.sum(\"dow_1\").alias(\"distrib_count_of_dow_1_p_prod\"),\n","                 F.sum(\"dow_2\").alias(\"distrib_count_of_dow_2_p_prod\"),\n","                 F.sum(\"dow_3\").alias(\"distrib_count_of_dow_3_p_prod\"),\n","                 F.sum(\"dow_4\").alias(\"distrib_count_of_dow_4_p_prod\"),\n","                 F.sum(\"dow_5\").alias(\"distrib_count_of_dow_5_p_prod\"),\n","                 F.sum(\"dow_6\").alias(\"distrib_count_of_dow_6_p_prod\"))\n","        )\n","        \n","        # Probability it is reordered after the first order\n","        total_orders = self.prior_orders_df.select(\"order_id\").distinct().count()\n","        \n","        df_with_prob_reord = (\n","            self.prior_orders_df.select(\"order_id\", \"user_id\")\n","            .join(self.prior_product_orders.select(\"product_id\", \"order_id\"), on=\"order_id\", how='left')\n","            .groupBy(\"product_id\", \"user_id\")\n","            .agg(F.count(\"order_id\").alias(\"order_count\"))\n","            .groupBy(\"product_id\")\n","            .agg(((F.sum(\"order_count\") / total_orders).alias(\"prob_of_being_reordered\")))\n","        )\n","        \n","        result_product_df = (\n","            df_with_avg_position_of_prod\n","            .join(df_with_freq_one_shot_ord_prods, on=\"product_id\", how='left')\n","            .join(df_with_freq_co_ocrd, on=\"product_id\", how='left')\n","            .join(df_with_avg_num_item_co_ocrd_in_ord, on = 'product_id', how=\"left\")\n","            .join(df_with_stats_of_streaks, on=\"product_id\", how='left')\n","            .join(df_with_prob_greater_5, on=\"product_id\", how=\"left\")\n","            .join(df_with_prob_greater_3, on=\"product_id\", how=\"left\")\n","            .join(df_with_prob_greater_2, on=\"product_id\", how=\"left\")\n","            .join(df_with_count_of_dow_p_prod, on=\"product_id\", how=\"left\")\n","            .join(df_with_prob_reord, on=\"product_id\", how=\"left\")\n","        )\n","\n","        long_cols = [field.name for field in result_product_df.schema.fields if isinstance(field.dataType, LongType)]\n","        columns_to_cast = {col_name: F.col(col_name).cast(DoubleType()) for col_name in long_cols}\n","        result_product_df = result_product_df.withColumns(columns_to_cast)\n","        return result_product_df\n","        \n","    def generate_user_product_related_features(self):\n","        \n","        # Number of orders in which the user purchases the item\n","        df_with_num_of_order_p_product = (\n","            self.prior_product_orders.select(\"order_id\", \"product_id\")\n","            .join(self.prior_orders_df.select(\"order_id\", \"user_id\"), how='left', on='order_id')\n","            .groupBy(\"user_id\", \"product_id\")\n","            .agg(F.count(\"order_id\").alias(\"num_of_ord_purch_p_prod\"))\n","        )\n","        \n","        # Position in the cart\n","        df_with_position_cart_p_usr_p_prod = (\n","            self.prior_product_orders.select(\"product_id\", \"add_to_cart_order\", \"order_id\")\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), how='left', on='order_id')\n","            .groupBy(\"user_id\", \"product_id\")\n","            .agg(F.mean(F.col(\"add_to_cart_order\")).alias(\"prod_mean_of_position_p_user\"))\n","        )\n","        \n","        # Co-occurrence statistics\n","        df_with_co_ocrd_stats_p_user_p_prod = (\n","            self.prior_product_orders.select(\"product_id\", \"order_id\").alias(\"df1\")\n","            .join(self.prior_orders_df.select(\"user_id\", \"order_id\"), on='order_id', how='left')\n","            .join(self.prior_product_orders.select(\"product_id\", \"order_id\").withColumnRenamed(\"product_id\", \"product_id_1\").alias(\"df2\"),\n","                  (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n","                  \"left\")\n","            .groupBy(\"user_id\", \"df1.product_id\")\n","            .agg(F.count(F.col(\"df2.product_id_1\")).alias(\"num_of_prod_co_ocrd_p_usr_p_prod\"))\n","        )\n","\n","        result_usr_prod_df = (\n","            df_with_num_of_order_p_product\n","            .join(df_with_position_cart_p_usr_p_prod,\n","                  on = ['user_id','product_id'], how=\"left\"\n","                 )\n","            .join(df_with_co_ocrd_stats_p_user_p_prod,\n","                  on = ['user_id','product_id'], how=\"left\"\n","                 )\n","        )   \n","        long_cols = [field.name for field in result_usr_prod_df.schema.fields if isinstance(field.dataType, LongType)]\n","        columns_to_cast = {col_name: F.col(col_name).cast(DoubleType()) for col_name in long_cols}\n","        result_usr_prod_df = result_usr_prod_df.withColumns(columns_to_cast)\n","        return result_usr_prod_df\n","\n","    def generate_time_related_features(self):\n","        # Counts by day of the week\n","        result_df = self.generate_user_related_features()\n","        \n","        df_with_count_of_dow = (\n","            self.prior_orders_df.select(\"order_id\", \"order_dow\")\n","            .groupBy(\"order_dow\")\n","            .agg(F.count(\"order_id\").alias(\"total_ord_count_p_dow\"))\n","        )\n","        \n","        # Counts by hour of the day\n","        df_with_count_of_ohod = (\n","            self.prior_orders_df.select(\"order_id\", \"order_hour_of_day\")\n","            .groupBy(\"order_hour_of_day\")\n","            .agg(F.count(\"order_id\").alias(\"total_ord_count_p_ohod\"))\n","        )\n","            \n","        result_time_df = (\n","            self.prior_orders_df.select(\"user_id\",\"order_id\",\"order_dow\",\"order_hour_of_day\")\n","            .join(df_with_count_of_dow, on=\"order_dow\", how=\"left\")\n","            .join(df_with_count_of_ohod, on=\"order_hour_of_day\", how=\"left\")\n","        ).withColumnsRenamed({\"order_dow\":\"dow\",\"order_hour_of_day\":\"hour_of_day\"})\n","        \n","        \n","        long_cols = [field.name for field in result_time_df.schema.fields if isinstance(field.dataType, LongType)]\n","        columns_to_cast = {col_name: F.col(col_name).cast(DoubleType()) for col_name in long_cols}\n","        result_time_df = result_time_df.withColumns(columns_to_cast)\n","        return result_time_df\n","\n","\n","    def generate_all_types_of_features(self):\n","        \n","        result_usr_prod_df = self.generate_user_product_related_features()\n","        result_time_df = self.generate_time_related_features()\n","        result_product_df = self.generate_product_related_features()\n","        result_usr_df = self.generate_user_related_features()\n","            \n","        final_prior_ord_train_df = (\n","            self.prior_product_orders.drop(\"add_to_cart_order\")\n","            .join(\n","                result_time_df , on = 'order_id',how='left'\n","            ).drop('order_id',\"dow\",\"hour_of_day\")\n","            .join(\n","                result_usr_df , on = 'user_id',how='left'\n","            )\n","            .join(\n","                result_product_df, on = 'product_id' , how = 'left'\n","            )\n","            .join(\n","                result_usr_prod_df , on = ['user_id','product_id'] , how='left'\n","            )\n","            \n","        )\n","        long_cols = [field.name for field in final_prior_ord_train_df.schema.fields if isinstance(field.dataType, StringType)]\n","        columns_to_cast = {col_name: F.col(col_name).cast(DoubleType()) for col_name in long_cols}\n","        final_prior_ord_train_df = final_prior_ord_train_df.withColumns(columns_to_cast)\n","\n","        return final_prior_ord_train_df\n","\n","        \n","def generate_test_set_features(user_stats_df,prods_stats_df,user_prod_stats_df,time_related_stats,test_set):\n","        \n","    user_df_list = [user_stats_df,user_prod_stats_df]\n","    product_df_list = [prods_stats_df,user_prod_stats_df]\n","    \n","    for i in user_df_list:\n","        \n","        if \"user_id\" not in i.columns:\n","            raise NameError(f\"'user_id' is missing in {i}\")\n","            \n","    for i in product_df_list:\n","        \n","        if \"product_id\" not in i.columns:\n","            raise NameError(f\"'product_id' is missing in {i}\")\n","        \n","    if \"user_id\"  not in test_set.columns and \"product_id\" not in test_set.columns:\n","        raise NameError(\"'user_id' and 'product_id' both are missing in test_set\")\n","        \n","    elif \"user_id\" not in test_set.columns:\n","        raise NameError(\"'user_id' not found in test_set\")\n","        \n","    elif \"product_id\" not in test_set.columns:\n","        raise NameError(\"'product_id' not found in test_set\")\n","        \n","    else:\n","        mean_dow_value = time_related_stats.groupBy(\"dow\").agg(\n","            F.mean(\"total_ord_count_p_dow\")\n","        ).collect()[0][0]\n","        \n","        mean_ohod_value = time_related_stats.groupBy(\"hour_of_day\").agg(\n","            F.mean(\"total_ord_count_p_ohod\")\n","        ).collect()[0][0]\n","        \n","        result_test_df = (\n","              \n","            test_set.withColumns({\n","                  \"time_mean_dow_count\":F.lit(mean_dow_value),\n","                  \"time_mean_ohod_count\":F.lit(mean_ohod_value)\n","            }).join(\n","                user_stats_df, on = 'user_id', how = 'left'\n","            )\n","            .join(\n","                prods_stats_df, on = 'product_id', how = 'left'\n","            )\n","            .join(\n","                user_prod_stats_df, on = ['user_id','product_id'], how = 'left'\n","            )\n","        )\n","        \n","    return result_test_df"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:00.604583Z","iopub.status.busy":"2024-11-03T05:54:00.603723Z","iopub.status.idle":"2024-11-03T05:54:01.072079Z","shell.execute_reply":"2024-11-03T05:54:01.070767Z","shell.execute_reply.started":"2024-11-03T05:54:00.604524Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from pyspark.sql import SparkSession,Window\n","import pyspark.sql.functions as F\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:01.074476Z","iopub.status.busy":"2024-11-03T05:54:01.073741Z","iopub.status.idle":"2024-11-03T05:54:06.551797Z","shell.execute_reply":"2024-11-03T05:54:06.550403Z","shell.execute_reply.started":"2024-11-03T05:54:01.074429Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/11/03 05:54:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["spark = SparkSession.builder.appName(\"instamart_analysis\") \\\n","    .config(\"spark.driver.memory\",\"25g\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:06.555742Z","iopub.status.busy":"2024-11-03T05:54:06.553844Z","iopub.status.idle":"2024-11-03T05:54:15.485303Z","shell.execute_reply":"2024-11-03T05:54:15.484062Z","shell.execute_reply.started":"2024-11-03T05:54:06.555692Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["orders_df = spark.read.csv('/kaggle/input/instacart-market-basket-analysis/orders.csv',header=True)\n","prior_product_orders = spark.read.csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__prior.csv\",header=True)\n","products_df = spark.read.csv(\"/kaggle/input/instacart-market-basket-analysis/products.csv\",header=True)\n","train_product_orders= spark.read.csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__train.csv\",header=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:15.487171Z","iopub.status.busy":"2024-11-03T05:54:15.486682Z","iopub.status.idle":"2024-11-03T05:54:15.688311Z","shell.execute_reply":"2024-11-03T05:54:15.686592Z","shell.execute_reply.started":"2024-11-03T05:54:15.487120Z"},"trusted":true},"outputs":[],"source":["prior_product_orders = prior_product_orders.select(\n","                                                       [F.col(col).cast(\"float\").alias(col) for col in  prior_product_orders.columns] \n","                                                        )\n","# convert the string col into the float for float.\n","orders_df = orders_df.select(\n","    [F.col(col).cast(\"float\").alias(col) if col !='eval_set' else F.col(col).alias(col) for col in orders_df.columns]\n",")\n","\n","train_product_orders = train_product_orders.select(\n","                                                       [F.col(col).cast(\"float\").alias(col) for col in  prior_product_orders.columns] \n","                                                        )"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:15.694239Z","iopub.status.busy":"2024-11-03T05:54:15.693697Z","iopub.status.idle":"2024-11-03T05:54:15.731253Z","shell.execute_reply":"2024-11-03T05:54:15.729701Z","shell.execute_reply.started":"2024-11-03T05:54:15.694182Z"},"trusted":true},"outputs":[],"source":["final_train_product_orders = train_product_orders.union(prior_product_orders)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:15.733629Z","iopub.status.busy":"2024-11-03T05:54:15.733095Z","iopub.status.idle":"2024-11-03T05:54:15.803070Z","shell.execute_reply":"2024-11-03T05:54:15.801708Z","shell.execute_reply.started":"2024-11-03T05:54:15.733572Z"},"trusted":true},"outputs":[],"source":["final_train_orders_df = orders_df.filter(F.col(\"eval_set\") != 'test').drop('eval_set')\n","test_orders_df = orders_df.filter(F.col(\"eval_set\") == 'test').select(\"order_id\",\"user_id\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Checking test_orders_df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:15.808762Z","iopub.status.busy":"2024-11-03T05:54:15.808247Z","iopub.status.idle":"2024-11-03T05:54:20.475732Z","shell.execute_reply":"2024-11-03T05:54:20.474509Z","shell.execute_reply.started":"2024-11-03T05:54:15.808708Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["75000"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_orders_df.count()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:20.478845Z","iopub.status.busy":"2024-11-03T05:54:20.477946Z","iopub.status.idle":"2024-11-03T05:54:25.461109Z","shell.execute_reply":"2024-11-03T05:54:25.459815Z","shell.execute_reply.started":"2024-11-03T05:54:20.478781Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["75000"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# check how many distinct user,order pairs is there\n","test_orders_df.select(\"user_id\").distinct().count()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:25.463920Z","iopub.status.busy":"2024-11-03T05:54:25.463364Z","iopub.status.idle":"2024-11-03T05:54:25.483103Z","shell.execute_reply":"2024-11-03T05:54:25.481590Z","shell.execute_reply.started":"2024-11-03T05:54:25.463860Z"},"trusted":true},"outputs":[],"source":["fet_gen = FeatureGenerator(final_train_product_orders,final_train_orders_df,products_df)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:25.500461Z","iopub.status.busy":"2024-11-03T05:54:25.494025Z","iopub.status.idle":"2024-11-03T05:54:43.443486Z","shell.execute_reply":"2024-11-03T05:54:43.442151Z","shell.execute_reply.started":"2024-11-03T05:54:25.500386Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["result_df = fet_gen.generate_user_related_features()\n","result_prod_df = fet_gen.generate_product_related_features()\n","result_user_prod_df = fet_gen.generate_user_product_related_features()\n","result_time_df=  fet_gen.generate_time_related_features()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:43.445968Z","iopub.status.busy":"2024-11-03T05:54:43.445582Z","iopub.status.idle":"2024-11-03T05:54:56.766195Z","shell.execute_reply":"2024-11-03T05:54:56.764787Z","shell.execute_reply.started":"2024-11-03T05:54:43.445927Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["final_prior_train_set = fet_gen.generate_all_types_of_features()"]},{"cell_type":"markdown","metadata":{},"source":["## checking training dataframe"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:56.768489Z","iopub.status.busy":"2024-11-03T05:54:56.767925Z","iopub.status.idle":"2024-11-03T05:54:56.774817Z","shell.execute_reply":"2024-11-03T05:54:56.773311Z","shell.execute_reply.started":"2024-11-03T05:54:56.768423Z"},"trusted":true},"outputs":[],"source":["# final_prior_train_set.count()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:54:56.776735Z","iopub.status.busy":"2024-11-03T05:54:56.776224Z","iopub.status.idle":"2024-11-03T05:54:56.854478Z","shell.execute_reply":"2024-11-03T05:54:56.853290Z","shell.execute_reply.started":"2024-11-03T05:54:56.776680Z"},"trusted":true},"outputs":[],"source":["# final_prior_train_set.dropDuplicates().count()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:58:38.729264Z","iopub.status.busy":"2024-11-03T05:58:38.728672Z","iopub.status.idle":"2024-11-03T05:58:38.796447Z","shell.execute_reply":"2024-11-03T05:58:38.795283Z","shell.execute_reply.started":"2024-11-03T05:58:38.729214Z"},"trusted":true},"outputs":[],"source":["# let's make test set from train set\n","test_set = (\n","    test_orders_df.select(\"user_id\")\n","                    .join(\n","                        final_train_orders_df,on='user_id',how='left'\n","                    ).select(\"user_id\",\"order_id\")\n","                    .join(\n","                        prior_product_orders.select(\"order_id\",\"product_id\") , on ='order_id',how='left'\n","                    )\n","                    .select(\"user_id\",\"product_id\").distinct()\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## checking test dataframe"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:58:42.463930Z","iopub.status.busy":"2024-11-03T05:58:42.463435Z","iopub.status.idle":"2024-11-03T05:59:50.633794Z","shell.execute_reply":"2024-11-03T05:59:50.632414Z","shell.execute_reply.started":"2024-11-03T05:58:42.463878Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["4833292"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# test_set.count()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T05:59:50.637095Z","iopub.status.busy":"2024-11-03T05:59:50.635718Z","iopub.status.idle":"2024-11-03T06:00:53.921943Z","shell.execute_reply":"2024-11-03T06:00:53.920724Z","shell.execute_reply.started":"2024-11-03T05:59:50.637015Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["4833292"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# test_set.distinct().count()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T06:01:23.661051Z","iopub.status.busy":"2024-11-03T06:01:23.660568Z","iopub.status.idle":"2024-11-03T06:01:44.397202Z","shell.execute_reply":"2024-11-03T06:01:44.395936Z","shell.execute_reply.started":"2024-11-03T06:01:23.660993Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["featured_test_set = generate_test_set_features(result_df,result_prod_df,result_user_prod_df,result_time_df,test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["final_prior_train_set.coalesce(1).write.csv(\"final_prior_train_set.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["featured_test_set.coalesce(1).write.csv(\"featured_test_set.csv\")\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T06:01:49.810198Z","iopub.status.busy":"2024-11-03T06:01:49.809723Z","iopub.status.idle":"2024-11-03T06:01:49.819345Z","shell.execute_reply":"2024-11-03T06:01:49.818005Z","shell.execute_reply.started":"2024-11-03T06:01:49.810153Z"},"trusted":true},"outputs":[],"source":["with open(\"train_set_columns.txt\",'w') as f:\n","    for column in final_prior_train_set.columns:\n","        f.write('%s,'%column)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T06:01:50.046870Z","iopub.status.busy":"2024-11-03T06:01:50.046377Z","iopub.status.idle":"2024-11-03T06:01:50.056136Z","shell.execute_reply":"2024-11-03T06:01:50.054664Z","shell.execute_reply.started":"2024-11-03T06:01:50.046824Z"},"trusted":true},"outputs":[],"source":["\n","with open(\"test_set_columns.txt\",'w') as f:\n","    for column in featured_test_set.columns:\n","        f.write('%s,'%column)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4931,"sourceId":7487,"sourceType":"datasetVersion"},{"sourceId":203945036,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
