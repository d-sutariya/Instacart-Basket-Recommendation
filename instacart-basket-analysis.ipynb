{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7487,"sourceType":"datasetVersion","datasetId":4931}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:48:01.850467Z","iopub.execute_input":"2024-10-09T07:48:01.850950Z","iopub.status.idle":"2024-10-09T07:49:12.926290Z","shell.execute_reply.started":"2024-10-09T07:48:01.850884Z","shell.execute_reply":"2024-10-09T07:49:12.924764Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=b668889260d6fef3b8d83f47aaeaffdb3aff900e9544dcd8000d92d1accf8da0\n  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.3\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport pyspark\nimport numpy as np\nfrom pyngrok import ngrok\nfrom pyspark.sql import SparkSession , Window\nfrom pyspark.sql import functions as F\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:49:12.928852Z","iopub.execute_input":"2024-10-09T07:49:12.929288Z","iopub.status.idle":"2024-10-09T07:49:13.071421Z","shell.execute_reply.started":"2024-10-09T07:49:12.929241Z","shell.execute_reply":"2024-10-09T07:49:13.069777Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create a SparkSession with custom memory settings\nspark = SparkSession.builder.appName(\"instamart_analysis\") \\\n    .config(\"spark.driver.memory\",\"25g\") \\\n    .getOrCreate()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:49:13.073216Z","iopub.execute_input":"2024-10-09T07:49:13.073911Z","iopub.status.idle":"2024-10-09T07:49:19.565528Z","shell.execute_reply.started":"2024-10-09T07:49:13.073864Z","shell.execute_reply":"2024-10-09T07:49:19.563800Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/10/09 07:49:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"def show_time(start):\n    return time.time()-start","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:49:19.569601Z","iopub.execute_input":"2024-10-09T07:49:19.570214Z","iopub.status.idle":"2024-10-09T07:49:19.576816Z","shell.execute_reply.started":"2024-10-09T07:49:19.570150Z","shell.execute_reply":"2024-10-09T07:49:19.575498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"departments_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/departments.csv\")\nproducts_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/products.csv\")\nprior_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__prior.csv\").repartition(12)\ntrain_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__train.csv\").repartition(8)\norders_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/orders.csv\").repartition(8)\naisels_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/aisles.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:49:19.579195Z","iopub.execute_input":"2024-10-09T07:49:19.579745Z","iopub.status.idle":"2024-10-09T07:50:16.974057Z","shell.execute_reply.started":"2024-10-09T07:49:19.579687Z","shell.execute_reply":"2024-10-09T07:50:16.972592Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Create a tunnel to the Spark UI\nngrok.set_auth_token('2kvaYw5ZiG5bL8iM8YJBVJPk1Ru_3C16mMgmpKEBYb28PPLUe')  # Optional: set your Ngrok auth token if you have one\ntunnel = ngrok.connect(4040)\nprint(\"Ngrok tunnel \\\"{}\\\" -> \\\"http://localhost:4040\\\"\".format(tunnel.public_url))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:16.976099Z","iopub.execute_input":"2024-10-09T07:50:16.977003Z","iopub.status.idle":"2024-10-09T07:50:19.192618Z","shell.execute_reply.started":"2024-10-09T07:50:16.976941Z","shell.execute_reply":"2024-10-09T07:50:19.190484Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Ngrok tunnel \"https://371c-34-34-2-26.ngrok-free.app\" -> \"http://localhost:4040\"                    \n","output_type":"stream"}]},{"cell_type":"code","source":"prior_product_orders.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.194775Z","iopub.execute_input":"2024-10-09T07:50:19.195224Z","iopub.status.idle":"2024-10-09T07:50:19.204425Z","shell.execute_reply.started":"2024-10-09T07:50:19.195179Z","shell.execute_reply":"2024-10-09T07:50:19.203237Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- add_to_cart_order: integer (nullable = true)\n |-- reordered: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.206147Z","iopub.execute_input":"2024-10-09T07:50:19.206674Z","iopub.status.idle":"2024-10-09T07:50:19.261320Z","shell.execute_reply.started":"2024-10-09T07:50:19.206599Z","shell.execute_reply":"2024-10-09T07:50:19.260083Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- user_id: integer (nullable = true)\n |-- eval_set: string (nullable = true)\n |-- order_number: integer (nullable = true)\n |-- order_dow: integer (nullable = true)\n |-- order_hour_of_day: integer (nullable = true)\n |-- days_since_prior_order: double (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.262826Z","iopub.execute_input":"2024-10-09T07:50:19.263308Z","iopub.status.idle":"2024-10-09T07:50:19.403104Z","shell.execute_reply.started":"2024-10-09T07:50:19.263255Z","shell.execute_reply":"2024-10-09T07:50:19.402019Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, user_id: int, eval_set: string, order_number: int, order_dow: int, order_hour_of_day: int, days_since_prior_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"train_orders_df = orders_df.filter(orders_df[\"eval_set\"] =='train').drop(\"eval_set\")\nprior_orders_df = orders_df.filter(orders_df[\"eval_set\"] == 'prior').drop(\"eval_set\")\ntrain_orders_df.cache()\ntrain_product_orders.cache()\nprior_orders_df.cache()\nprior_product_orders.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.408228Z","iopub.execute_input":"2024-10-09T07:50:19.408653Z","iopub.status.idle":"2024-10-09T07:50:19.605936Z","shell.execute_reply.started":"2024-10-09T07:50:19.408596Z","shell.execute_reply":"2024-10-09T07:50:19.604749Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, product_id: int, add_to_cart_order: int, reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often user has reorderd\nprior_product_orders.select(\"reordered\",\"order_id\").join(\n        prior_orders_df.select(\"user_id\",\"order_id\"),how=\"left\",on=\"order_id\"\n    ).select(\"user_id\",\"reordered\") \\\n     .groupBy(\"user_id\").agg(\n            F.count(F.col(\"reordered\")).alias(\"frequency of reorder\")\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.607727Z","iopub.execute_input":"2024-10-09T07:50:19.608449Z","iopub.status.idle":"2024-10-09T07:50:19.785241Z","shell.execute_reply.started":"2024-10-09T07:50:19.608393Z","shell.execute_reply":"2024-10-09T07:50:19.783910Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, frequency of reorder: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# time since privious order\nprior_orders_df.select(\"user_id\",\"days_since_prior_order\",\"order_hour_of_day\",\"order_number\",\"order_id\") \\\n                .withColumn(\"privious_order_hour\",\n                            F.lag(\"order_hour_of_day\",1) \\\n                            .over(Window.partitionBy(\"user_id\").orderBy(\"order_number\"))) \\\n                .withColumn(\"time_since_Last_order\",\n                            F.col(\"days_since_prior_order\") * 24 + \n                            F.col(\"order_hour_of_day\") - \n                            F.col(\"privious_order_hour\") \n                           ) \\\n                .select(\"order_id\",\"time_since_last_order\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:19.787171Z","iopub.execute_input":"2024-10-09T07:50:19.788068Z","iopub.status.idle":"2024-10-09T07:50:20.014309Z","shell.execute_reply.started":"2024-10-09T07:50:19.788008Z","shell.execute_reply":"2024-10-09T07:50:20.013136Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, time_since_last_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"#time of the day user visits\nprior_orders_df.select(\"user_id\" , \"order_hour_of_day\",\"order_id\") \\\n                .groupBy(\"user_id\",\"order_hour_of_day\") \\\n                .agg(F.count(\"order_id\").alias(\"frequency\")) \\\n                .groupBy(\"user_id\") \\\n                .agg(F.max(\"frequency\").alias(\"maximum_frquency\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.016158Z","iopub.execute_input":"2024-10-09T07:50:20.017237Z","iopub.status.idle":"2024-10-09T07:50:20.154312Z","shell.execute_reply.started":"2024-10-09T07:50:20.017178Z","shell.execute_reply":"2024-10-09T07:50:20.152929Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, maximum_frquency: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# whether user has ordered glutan free , organic , Asian item or not\nprior_product_orders.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.156324Z","iopub.execute_input":"2024-10-09T07:50:20.157543Z","iopub.status.idle":"2024-10-09T07:50:20.167686Z","shell.execute_reply.started":"2024-10-09T07:50:20.157482Z","shell.execute_reply":"2024-10-09T07:50:20.166023Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- add_to_cart_order: integer (nullable = true)\n |-- reordered: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"products_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.171045Z","iopub.execute_input":"2024-10-09T07:50:20.172396Z","iopub.status.idle":"2024-10-09T07:50:20.181224Z","shell.execute_reply.started":"2024-10-09T07:50:20.172329Z","shell.execute_reply":"2024-10-09T07:50:20.179735Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"root\n |-- product_id: integer (nullable = true)\n |-- product_name: string (nullable = true)\n |-- aisle_id: string (nullable = true)\n |-- department_id: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# does the user have ordered asian , gluten free, or organic item \nprior_product_orders.select(\"order_id\",\"product_id\") \\\n            .join(products_df.select(\"product_id\",\"product_name\"), on=\"product_id\", how='left') \\\n            .join(prior_orders_df.select(\"user_id\",\"order_id\"), on=\"order_id\", how='left') \\\n            .groupBy(\"user_id\", \"order_id\") \\\n            .agg(F.collect_list(\"product_name\").alias(\"list_of_products\")) \\\n            .withColumn(\"normalized_list\", F.expr(\"transform(list_of_products, x -> lower(x))\")) \\\n            .withColumn(\"contains_or_not\", \n                F.expr(\"exists(normalized_list,x -> x like '%organic%')\")\n              | F.expr(\"exists(normalized_list, x -> x like '%asian%')\")\n              | F.expr(\"exists(normalized_list, x-> x like '%gluten free%')\")\n            ) \\\n            .filter(F.col(\"contains_or_not\") == True) \\\n            .select(\"user_id\", \"order_id\") ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-09T07:50:20.183074Z","iopub.execute_input":"2024-10-09T07:50:20.183971Z","iopub.status.idle":"2024-10-09T07:50:20.616288Z","shell.execute_reply.started":"2024-10-09T07:50:20.183916Z","shell.execute_reply":"2024-10-09T07:50:20.615121Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, order_id: int]"},"metadata":{}}]},{"cell_type":"code","source":"# feature based on order size \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\") , on=\"order_id\", how=\"left\") \\\n                    .groupBy(\"user_id\",'order_id') \\\n                    .agg(\n                            F.count(F.col(\"product_id\")).alias(\"count_of_product\")\n                        ) \\\n                    .groupBy(\"user_id\") \\\n                    .agg(\n                            F.max(F.col(\"count_of_product\")).alias(\"max_count_of_products\"),\n                            F.min(F.col(\"count_of_product\")).alias(\"min_count_of_products\"),\n                            F.mean(F.col(\"count_of_product\")).alias(\"mean_count_of_products\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.621865Z","iopub.execute_input":"2024-10-09T07:50:20.623959Z","iopub.status.idle":"2024-10-09T07:50:20.756324Z","shell.execute_reply.started":"2024-10-09T07:50:20.623892Z","shell.execute_reply":"2024-10-09T07:50:20.755177Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, max_count_of_products: bigint, min_count_of_products: bigint, mean_count_of_products: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many of the user’s orders contained no previously purchased items\nprior_product_orders.select(\"order_id\",\"reordered\") \\\n                    .join(prior_orders_df.select(\"order_id\",\"user_id\") , on = 'order_id' , how = 'left') \\\n                    .groupBy(\"user_Id\",\"order_id\") \\\n                    .agg(\n                            F.collect_list(F.col(\"reordered\")).alias(\"reordered_array\")\n                        ) \\\n                    .withColumn(\"doesnt_contains_reordered\" ,\n                            F.when(F.array_contains(\"reordered_array\",1),0).otherwise(1)\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.758388Z","iopub.execute_input":"2024-10-09T07:50:20.759294Z","iopub.status.idle":"2024-10-09T07:50:20.883772Z","shell.execute_reply.started":"2024-10-09T07:50:20.759235Z","shell.execute_reply":"2024-10-09T07:50:20.882609Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_Id: int, order_id: int, reordered_array: array<int>, doesnt_contains_reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often the item has purchaced \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                     .groupBy(\"product_id\") \\\n                     .agg(\n                             F.count(F.col(\"order_id\")).alias(\"product_count\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.887409Z","iopub.execute_input":"2024-10-09T07:50:20.887914Z","iopub.status.idle":"2024-10-09T07:50:20.938257Z","shell.execute_reply.started":"2024-10-09T07:50:20.887859Z","shell.execute_reply":"2024-10-09T07:50:20.937156Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_count: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# position of product \nprior_product_orders.select(\"product_id\",\"add_to_cart_order\") \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.mean(F.col(\"add_to_cart_order\")).alias(\"product_mean_of_position\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.939959Z","iopub.execute_input":"2024-10-09T07:50:20.941135Z","iopub.status.idle":"2024-10-09T07:50:20.992578Z","shell.execute_reply.started":"2024-10-09T07:50:20.941079Z","shell.execute_reply":"2024-10-09T07:50:20.991465Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_mean_of_position: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many users buy it as \"one shot\" item\nprior_product_orders.select(\"order_id\",\"product_id\") \\\n                    .groupBy(\"order_id\") \\\n                    .agg(F.collect_list(\"product_id\").alias(\"list_of_products\")) \\\n                    .withColumn(\"is_one_shot_order\",\n                                   F.when(F.size(F.col(\"list_of_products\")) == 1,1).otherwise(0)\n                               ) \\\n                    .withColumn(\"product_id\",F.explode(F.col(\"list_of_products\"))) \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\"),on=\"order_id\",how='left') \\\n                    .groupBy(\"product_id\",\"user_id\") \\\n                    .agg(F.collect_list(F.col(\"is_one_shot_order\")).alias(\"is_one_shot_order_list\")) \\\n                    .withColumn(\"has_user_purchased_one_shot\",F.when(F.array_contains(\"is_one_shot_order_list\",1),1).otherwise(0)) \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.sum(F.col(\"has_user_purchased_one_shot\")).alias(\"number_of_user_purchased_item\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:20.994071Z","iopub.execute_input":"2024-10-09T07:50:20.994521Z","iopub.status.idle":"2024-10-09T07:50:21.213982Z","shell.execute_reply.started":"2024-10-09T07:50:20.994471Z","shell.execute_reply":"2024-10-09T07:50:21.212766Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, number_of_user_purchased_item: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# Stats on the number of items that co-occur with this item\n\n# 1. number of time that a item has co occured.\n# Perform a self-join on prior_product_orders\nresult_df = (\n    prior_product_orders\n    .select(\"product_id\", \"order_id\")\n    .alias(\"df1\")\n    .join(\n        prior_product_orders.select(\"product_id\", \"order_id\")\n        .withColumnRenamed(\"product_id\", \"product_id_1\")\n        .alias(\"df2\"),\n        (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n        \"left\"\n    )\n    .groupBy(\"df1.product_id\")\n    .agg(F.count(F.col(\"df2.product_id_1\")).alias(\"number_of_product_co_occurred\"))\n)\n\n# 2 average number of items that is co ocuured with this item in single order\n\nresult_df = (\n                prior_product_orders.select(\"product_id\",\"order_id\").alias(\"ppo1\") \n                .join(\n                    prior_product_orders.select(\"product_id\",\"order_id\")\n                    .alias(\"ppo2\"),\n                    (F.col(\"ppo1.order_id\") == F.col(\"ppo2.order_id\")) & \n                    (F.col(\"ppo1.product_id\") != F.col(\"ppo2.product_id\")),\n                    how='left'\n                ) \n                .groupBy(\"ppo1.product_id\",\"ppo1.order_id\")\n                .agg(F.count(F.col(\"ppo2.product_id\")).alias(\"count_of_co_ocuured_product_per_order\"))\n                .groupBy(\"ppo1.product_id\")\n                .agg(\n                    F.mean(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"mean_of_co_ocuured_product_per_order\"),\n                    F.min(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"min_of_co_ocuured_product_per_order\"),\n                    F.max(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"max_of_co_ocuured_product_per_order\"),\n\n                )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T07:50:21.215471Z","iopub.execute_input":"2024-10-09T07:50:21.216206Z","iopub.status.idle":"2024-10-09T07:50:21.492239Z","shell.execute_reply.started":"2024-10-09T07:50:21.216151Z","shell.execute_reply":"2024-10-09T07:50:21.490920Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Stats on the order streak\n\n# 1. let's add the flag whether streak is continued or not\ndf_with_flag= (\n\n    prior_product_orders.select(\"product_id\",\"order_id\")\n                        .join(\n                                prior_orders_df.select(\"user_id\",\"order_number\",\"order_id\"),\n                                how ='left',\n                                on = 'order_id' \n                            )\n                        .withColumn(\"next_order_number\",\n                            F.lead(F.col(\"order_number\"),1).over(Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\"))\n                        )\n                        .withColumn(\"is_streak_continued_flag\",\n                               F.when(F.col(\"next_order_number\") - F.col(\"order_number\") == 1,1)\n                                    .otherwise(0)\n                            )\n)\n# 2. let's assign an unique id to each streak of a perticular user and product.\n\nw1 = Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\")\nw2 = Window.partitionBy(\"user_id\",\"product_id\",\"is_streak_continued_flag\").orderBy(\"order_number\")\n\n# by using the above window we can create unique id for streak named grp then can find streak leangth.\ndf_with_streak_length = (\n    df_with_flag.withColumn(\"grp\",F.row_number().over(w1) - F.row_number().over(w2))\n                .groupBy(\"user_id\",\"product_id\",\"grp\")\n                .agg(\n                    F.count(\"order_number\").alias(\"length_of_streaks\")\n                )\n)\n\n# finally , summarize it over each prodcut rather than per user per product.\ndf_with_stats_of_streaks = (\n    df_with_streak_length.select(\"product_id\",\"length_of_streaks\",\"grp\")\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count('grp').alias(\"Total_streak_of_this_product\"),\n                             F.mean(\"length_of_streaks\").alias(\"mean_of_streaks_of_this_product\"),\n                             F.min(\"length_of_streaks\").alias(\"max_of_streaks_of_this_product\"),\n                             F.max(\"length_of_streaks\").alias(\"min_of_streaks_of_this_product\")\n                         \n                         )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T11:17:55.393773Z","iopub.execute_input":"2024-10-09T11:17:55.394259Z","iopub.status.idle":"2024-10-09T11:17:55.609193Z","shell.execute_reply.started":"2024-10-09T11:17:55.394216Z","shell.execute_reply":"2024-10-09T11:17:55.607765Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Probability of being reordered within N orders\n\n# we have already counted the lenght of the streaks so if it is >= 5 then it will be added in probability.\n\ndf_with_prob_greater_5 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_5\",\n                                        F.when(F.col(\"length_of_streaks\") >= 5,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_5\").alias(\"total_streaks_greater_than_5\")\n                         )\n                         .withColumn(\"prob_of_reordered_5\",\n                             ( F.col(\"total_streaks_greater_than_5\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_5\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T11:15:43.937769Z","iopub.execute_input":"2024-10-09T11:15:43.938367Z","iopub.status.idle":"2024-10-09T11:15:44.018140Z","shell.execute_reply.started":"2024-10-09T11:15:43.938320Z","shell.execute_reply":"2024-10-09T11:15:44.016737Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 2 then it will be added in probability.\n\ndf_with_prob_greater_2 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_2\",\n                                        F.when(F.col(\"length_of_streaks\") >= 2,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_2\").alias(\"total_streaks_greater_than_2\")\n                         )\n                         .withColumn(\"prob_of_reordered_2\",\n                             ( F.col(\"total_streaks_greater_than_2\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_2\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T11:16:38.914086Z","iopub.execute_input":"2024-10-09T11:16:38.914612Z","iopub.status.idle":"2024-10-09T11:16:38.986397Z","shell.execute_reply.started":"2024-10-09T11:16:38.914563Z","shell.execute_reply":"2024-10-09T11:16:38.985121Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 3 then it will be added in probability.\n\ndf_with_prob_greater_3 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_3\",\n                                        F.when(F.col(\"length_of_streaks\") >= 3,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_3\").alias(\"total_streaks_greater_than_3\")\n                         )\n                         .withColumn(\"prob_of_reordered_3\",\n                             ( F.col(\"total_streaks_greater_than_3\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_3\")\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T11:16:54.348835Z","iopub.execute_input":"2024-10-09T11:16:54.350099Z","iopub.status.idle":"2024-10-09T11:16:54.427386Z","shell.execute_reply.started":"2024-10-09T11:16:54.350016Z","shell.execute_reply":"2024-10-09T11:16:54.425982Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}