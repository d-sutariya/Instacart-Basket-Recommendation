{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7487,"sourceType":"datasetVersion","datasetId":4931}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:28:35.505411Z","iopub.execute_input":"2024-10-09T12:28:35.506436Z","iopub.status.idle":"2024-10-09T12:29:44.533256Z","shell.execute_reply.started":"2024-10-09T12:28:35.506380Z","shell.execute_reply":"2024-10-09T12:29:44.531760Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=38ce2e8e2cbcc0a0806cc28db16be058cddbec26a25b866ca9d48269cb82bf05\n  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.3\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport pyspark\nimport numpy as np\nfrom pyngrok import ngrok\nfrom pyspark.sql import SparkSession , Window\nfrom pyspark.sql import functions as F\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:29:44.536094Z","iopub.execute_input":"2024-10-09T12:29:44.536517Z","iopub.status.idle":"2024-10-09T12:29:44.665601Z","shell.execute_reply.started":"2024-10-09T12:29:44.536461Z","shell.execute_reply":"2024-10-09T12:29:44.664435Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create a SparkSession with custom memory settings\nspark = SparkSession.builder.appName(\"instamart_analysis\") \\\n    .config(\"spark.driver.memory\",\"25g\") \\\n    .getOrCreate()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:29:44.667096Z","iopub.execute_input":"2024-10-09T12:29:44.667891Z","iopub.status.idle":"2024-10-09T12:29:50.383244Z","shell.execute_reply.started":"2024-10-09T12:29:44.667835Z","shell.execute_reply":"2024-10-09T12:29:50.381946Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/10/09 12:29:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"def show_time(start):\n    return time.time()-start","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:29:50.386022Z","iopub.execute_input":"2024-10-09T12:29:50.386433Z","iopub.status.idle":"2024-10-09T12:29:50.392203Z","shell.execute_reply.started":"2024-10-09T12:29:50.386388Z","shell.execute_reply":"2024-10-09T12:29:50.391154Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"departments_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/departments.csv\")\nproducts_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/products.csv\")\nprior_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__prior.csv\").repartition(12)\ntrain_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__train.csv\").repartition(8)\norders_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/orders.csv\").repartition(8)\naisels_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/aisles.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:29:50.393661Z","iopub.execute_input":"2024-10-09T12:29:50.394055Z","iopub.status.idle":"2024-10-09T12:30:46.706000Z","shell.execute_reply.started":"2024-10-09T12:29:50.394015Z","shell.execute_reply":"2024-10-09T12:30:46.704591Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Create a tunnel to the Spark UI\nngrok.set_auth_token('2kvaYw5ZiG5bL8iM8YJBVJPk1Ru_3C16mMgmpKEBYb28PPLUe')  # Optional: set your Ngrok auth token if you have one\ntunnel = ngrok.connect(4040)\nprint(\"Ngrok tunnel \\\"{}\\\" -> \\\"http://localhost:4040\\\"\".format(tunnel.public_url))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:47.004264Z","iopub.execute_input":"2024-10-09T12:30:47.004707Z","iopub.status.idle":"2024-10-09T12:30:48.114084Z","shell.execute_reply.started":"2024-10-09T12:30:47.004657Z","shell.execute_reply":"2024-10-09T12:30:48.112918Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Ngrok tunnel \"https://36b6-34-121-53-226.ngrok-free.app\" -> \"http://localhost:4040\"                 \n","output_type":"stream"}]},{"cell_type":"code","source":"prior_product_orders.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.115536Z","iopub.execute_input":"2024-10-09T12:30:48.115906Z","iopub.status.idle":"2024-10-09T12:30:48.125185Z","shell.execute_reply.started":"2024-10-09T12:30:48.115865Z","shell.execute_reply":"2024-10-09T12:30:48.123988Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- add_to_cart_order: integer (nullable = true)\n |-- reordered: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.126728Z","iopub.execute_input":"2024-10-09T12:30:48.127189Z","iopub.status.idle":"2024-10-09T12:30:48.135374Z","shell.execute_reply.started":"2024-10-09T12:30:48.127146Z","shell.execute_reply":"2024-10-09T12:30:48.133891Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- user_id: integer (nullable = true)\n |-- eval_set: string (nullable = true)\n |-- order_number: integer (nullable = true)\n |-- order_dow: integer (nullable = true)\n |-- order_hour_of_day: integer (nullable = true)\n |-- days_since_prior_order: double (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.137168Z","iopub.execute_input":"2024-10-09T12:30:48.137785Z","iopub.status.idle":"2024-10-09T12:30:48.282839Z","shell.execute_reply.started":"2024-10-09T12:30:48.137722Z","shell.execute_reply":"2024-10-09T12:30:48.281566Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, user_id: int, eval_set: string, order_number: int, order_dow: int, order_hour_of_day: int, days_since_prior_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"train_orders_df = orders_df.filter(orders_df[\"eval_set\"] =='train').drop(\"eval_set\")\nprior_orders_df = orders_df.filter(orders_df[\"eval_set\"] == 'prior').drop(\"eval_set\")\ntrain_orders_df.cache()\ntrain_product_orders.cache()\nprior_orders_df.cache()\nprior_product_orders.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.284548Z","iopub.execute_input":"2024-10-09T12:30:48.284940Z","iopub.status.idle":"2024-10-09T12:30:48.460444Z","shell.execute_reply.started":"2024-10-09T12:30:48.284898Z","shell.execute_reply":"2024-10-09T12:30:48.459064Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, product_id: int, add_to_cart_order: int, reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often user has reorderd\nprior_product_orders.select(\"reordered\",\"order_id\").join(\n        prior_orders_df.select(\"user_id\",\"order_id\"),how=\"left\",on=\"order_id\"\n    ).select(\"user_id\",\"reordered\") \\\n     .groupBy(\"user_id\").agg(\n            F.count(F.col(\"reordered\")).alias(\"frequency of reorder\")\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.463569Z","iopub.execute_input":"2024-10-09T12:30:48.464791Z","iopub.status.idle":"2024-10-09T12:30:48.630576Z","shell.execute_reply.started":"2024-10-09T12:30:48.464724Z","shell.execute_reply":"2024-10-09T12:30:48.629319Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, frequency of reorder: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# time since privious order\nprior_orders_df.select(\"user_id\",\"days_since_prior_order\",\"order_hour_of_day\",\"order_number\",\"order_id\") \\\n                .withColumn(\"privious_order_hour\",\n                            F.lag(\"order_hour_of_day\",1) \\\n                            .over(Window.partitionBy(\"user_id\").orderBy(\"order_number\"))) \\\n                .withColumn(\"time_since_Last_order\",\n                            F.col(\"days_since_prior_order\") * 24 + \n                            F.col(\"order_hour_of_day\") - \n                            F.col(\"privious_order_hour\") \n                           ) \\\n                .select(\"order_id\",\"time_since_last_order\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.632894Z","iopub.execute_input":"2024-10-09T12:30:48.633852Z","iopub.status.idle":"2024-10-09T12:30:48.801374Z","shell.execute_reply.started":"2024-10-09T12:30:48.633795Z","shell.execute_reply":"2024-10-09T12:30:48.800289Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, time_since_last_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"#time of the day user visits\nprior_orders_df.select(\"user_id\" , \"order_hour_of_day\",\"order_id\") \\\n                .groupBy(\"user_id\",\"order_hour_of_day\") \\\n                .agg(F.count(\"order_id\").alias(\"frequency\")) \\\n                .groupBy(\"user_id\") \\\n                .agg(F.max(\"frequency\").alias(\"maximum_frquency\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.806645Z","iopub.execute_input":"2024-10-09T12:30:48.807409Z","iopub.status.idle":"2024-10-09T12:30:48.889277Z","shell.execute_reply.started":"2024-10-09T12:30:48.807354Z","shell.execute_reply":"2024-10-09T12:30:48.888102Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, maximum_frquency: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# whether user has ordered glutan free , organic , Asian item or not\nprior_product_orders.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.891365Z","iopub.execute_input":"2024-10-09T12:30:48.892292Z","iopub.status.idle":"2024-10-09T12:30:48.900762Z","shell.execute_reply.started":"2024-10-09T12:30:48.892225Z","shell.execute_reply":"2024-10-09T12:30:48.899362Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- add_to_cart_order: integer (nullable = true)\n |-- reordered: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"products_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:48.903028Z","iopub.execute_input":"2024-10-09T12:30:48.903977Z","iopub.status.idle":"2024-10-09T12:30:48.911927Z","shell.execute_reply.started":"2024-10-09T12:30:48.903922Z","shell.execute_reply":"2024-10-09T12:30:48.910583Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"root\n |-- product_id: integer (nullable = true)\n |-- product_name: string (nullable = true)\n |-- aisle_id: string (nullable = true)\n |-- department_id: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# does the user have ordered asian , gluten free, or organic item \nprior_product_orders.select(\"order_id\",\"product_id\") \\\n            .join(products_df.select(\"product_id\",\"product_name\"), on=\"product_id\", how='left') \\\n            .join(prior_orders_df.select(\"user_id\",\"order_id\"), on=\"order_id\", how='left') \\\n            .groupBy(\"user_id\", \"order_id\") \\\n            .agg(F.collect_list(\"product_name\").alias(\"list_of_products\")) \\\n            .withColumn(\"normalized_list\", F.expr(\"transform(list_of_products, x -> lower(x))\")) \\\n            .withColumn(\"contains_or_not\", \n                F.expr(\"exists(normalized_list,x -> x like '%organic%')\")\n              | F.expr(\"exists(normalized_list, x -> x like '%asian%')\")\n              | F.expr(\"exists(normalized_list, x-> x like '%gluten free%')\")\n            ) \\\n            .filter(F.col(\"contains_or_not\") == True) \\\n            .select(\"user_id\", \"order_id\") ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-09T12:30:48.914563Z","iopub.execute_input":"2024-10-09T12:30:48.915690Z","iopub.status.idle":"2024-10-09T12:30:49.270567Z","shell.execute_reply.started":"2024-10-09T12:30:48.915576Z","shell.execute_reply":"2024-10-09T12:30:49.269418Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, order_id: int]"},"metadata":{}}]},{"cell_type":"code","source":"# feature based on order size \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\") , on=\"order_id\", how=\"left\") \\\n                    .groupBy(\"user_id\",'order_id') \\\n                    .agg(\n                            F.count(F.col(\"product_id\")).alias(\"count_of_product\")\n                        ) \\\n                    .groupBy(\"user_id\") \\\n                    .agg(\n                            F.max(F.col(\"count_of_product\")).alias(\"max_count_of_products\"),\n                            F.min(F.col(\"count_of_product\")).alias(\"min_count_of_products\"),\n                            F.mean(F.col(\"count_of_product\")).alias(\"mean_count_of_products\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.275715Z","iopub.execute_input":"2024-10-09T12:30:49.276851Z","iopub.status.idle":"2024-10-09T12:30:49.393782Z","shell.execute_reply.started":"2024-10-09T12:30:49.276791Z","shell.execute_reply":"2024-10-09T12:30:49.392543Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, max_count_of_products: bigint, min_count_of_products: bigint, mean_count_of_products: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many of the user’s orders contained no previously purchased items\nprior_product_orders.select(\"order_id\",\"reordered\") \\\n                    .join(prior_orders_df.select(\"order_id\",\"user_id\") , on = 'order_id' , how = 'left') \\\n                    .groupBy(\"user_Id\",\"order_id\") \\\n                    .agg(\n                            F.collect_list(F.col(\"reordered\")).alias(\"reordered_array\")\n                        ) \\\n                    .withColumn(\"doesnt_contains_reordered\" ,\n                            F.when(F.array_contains(\"reordered_array\",1),0).otherwise(1)\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.396835Z","iopub.execute_input":"2024-10-09T12:30:49.397733Z","iopub.status.idle":"2024-10-09T12:30:49.503580Z","shell.execute_reply.started":"2024-10-09T12:30:49.397665Z","shell.execute_reply":"2024-10-09T12:30:49.502382Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_Id: int, order_id: int, reordered_array: array<int>, doesnt_contains_reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often the item has purchaced \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                     .groupBy(\"product_id\") \\\n                     .agg(\n                             F.count(F.col(\"order_id\")).alias(\"product_count\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.504910Z","iopub.execute_input":"2024-10-09T12:30:49.505385Z","iopub.status.idle":"2024-10-09T12:30:49.547765Z","shell.execute_reply.started":"2024-10-09T12:30:49.505329Z","shell.execute_reply":"2024-10-09T12:30:49.546555Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_count: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# position of product \nprior_product_orders.select(\"product_id\",\"add_to_cart_order\") \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.mean(F.col(\"add_to_cart_order\")).alias(\"product_mean_of_position\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.549430Z","iopub.execute_input":"2024-10-09T12:30:49.550871Z","iopub.status.idle":"2024-10-09T12:30:49.599693Z","shell.execute_reply.started":"2024-10-09T12:30:49.550811Z","shell.execute_reply":"2024-10-09T12:30:49.598499Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_mean_of_position: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many users buy it as \"one shot\" item\nprior_product_orders.select(\"order_id\",\"product_id\") \\\n                    .groupBy(\"order_id\") \\\n                    .agg(F.collect_list(\"product_id\").alias(\"list_of_products\")) \\\n                    .withColumn(\"is_one_shot_order\",\n                                   F.when(F.size(F.col(\"list_of_products\")) == 1,1).otherwise(0)\n                               ) \\\n                    .withColumn(\"product_id\",F.explode(F.col(\"list_of_products\"))) \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\"),on=\"order_id\",how='left') \\\n                    .groupBy(\"product_id\",\"user_id\") \\\n                    .agg(F.collect_list(F.col(\"is_one_shot_order\")).alias(\"is_one_shot_order_list\")) \\\n                    .withColumn(\"has_user_purchased_one_shot\",F.when(F.array_contains(\"is_one_shot_order_list\",1),1).otherwise(0)) \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.sum(F.col(\"has_user_purchased_one_shot\")).alias(\"number_of_user_purchased_item\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.601363Z","iopub.execute_input":"2024-10-09T12:30:49.601814Z","iopub.status.idle":"2024-10-09T12:30:49.798339Z","shell.execute_reply.started":"2024-10-09T12:30:49.601773Z","shell.execute_reply":"2024-10-09T12:30:49.797399Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, number_of_user_purchased_item: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# Stats on the number of items that co-occur with this item\n\n# 1. number of time that a item has co occured.\n# Perform a self-join on prior_product_orders\nresult_df = (\n    prior_product_orders\n    .select(\"product_id\", \"order_id\")\n    .alias(\"df1\")\n    .join(\n        prior_product_orders.select(\"product_id\", \"order_id\")\n        .withColumnRenamed(\"product_id\", \"product_id_1\")\n        .alias(\"df2\"),\n        (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n        \"left\"\n    )\n    .groupBy(\"df1.product_id\")\n    .agg(F.count(F.col(\"df2.product_id_1\")).alias(\"number_of_product_co_occurred\"))\n)\n\n# 2 average number of items that is co ocuured with this item in single order\n\nresult_df = (\n                prior_product_orders.select(\"product_id\",\"order_id\").alias(\"ppo1\") \n                .join(\n                    prior_product_orders.select(\"product_id\",\"order_id\")\n                    .alias(\"ppo2\"),\n                    (F.col(\"ppo1.order_id\") == F.col(\"ppo2.order_id\")) & \n                    (F.col(\"ppo1.product_id\") != F.col(\"ppo2.product_id\")),\n                    how='left'\n                ) \n                .groupBy(\"ppo1.product_id\",\"ppo1.order_id\")\n                .agg(F.count(F.col(\"ppo2.product_id\")).alias(\"count_of_co_ocuured_product_per_order\"))\n                .groupBy(\"ppo1.product_id\")\n                .agg(\n                    F.mean(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"mean_of_co_ocuured_product_per_order\"),\n                    F.min(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"min_of_co_ocuured_product_per_order\"),\n                    F.max(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"max_of_co_ocuured_product_per_order\"),\n\n                )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:49.802594Z","iopub.execute_input":"2024-10-09T12:30:49.802987Z","iopub.status.idle":"2024-10-09T12:30:50.026338Z","shell.execute_reply.started":"2024-10-09T12:30:49.802945Z","shell.execute_reply":"2024-10-09T12:30:50.025123Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Stats on the order streak\n\n# 1. let's add the flag whether streak is continued or not\ndf_with_flag= (\n\n    prior_product_orders.select(\"product_id\",\"order_id\")\n                        .join(\n                                prior_orders_df.select(\"user_id\",\"order_number\",\"order_id\"),\n                                how ='left',\n                                on = 'order_id' \n                            )\n                        .withColumn(\"next_order_number\",\n                            F.lead(F.col(\"order_number\"),1).over(Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\"))\n                        )\n                        .withColumn(\"is_streak_continued_flag\",\n                               F.when(F.col(\"next_order_number\") - F.col(\"order_number\") == 1,1)\n                                    .otherwise(0)\n                            )\n)\n# 2. let's assign an unique id to each streak of a perticular user and product.\n\nw1 = Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\")\nw2 = Window.partitionBy(\"user_id\",\"product_id\",\"is_streak_continued_flag\").orderBy(\"order_number\")\n\n# by using the above window we can create unique id for streak named grp then can find streak leangth.\ndf_with_streak_length = (\n    df_with_flag.withColumn(\"grp\",F.row_number().over(w1) - F.row_number().over(w2))\n                .groupBy(\"user_id\",\"product_id\",\"grp\")\n                .agg(\n                    F.count(\"order_number\").alias(\"length_of_streaks\")\n                )\n)\n\n# finally , summarize it over each prodcut rather than per user per product.\ndf_with_stats_of_streaks = (\n    df_with_streak_length.select(\"product_id\",\"length_of_streaks\",\"grp\")\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count('grp').alias(\"Total_streak_of_this_product\"),\n                             F.mean(\"length_of_streaks\").alias(\"mean_of_streaks_of_this_product\"),\n                             F.min(\"length_of_streaks\").alias(\"max_of_streaks_of_this_product\"),\n                             F.max(\"length_of_streaks\").alias(\"min_of_streaks_of_this_product\")\n                         \n                         )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:50.028420Z","iopub.execute_input":"2024-10-09T12:30:50.028905Z","iopub.status.idle":"2024-10-09T12:30:50.274405Z","shell.execute_reply.started":"2024-10-09T12:30:50.028850Z","shell.execute_reply":"2024-10-09T12:30:50.273227Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Probability of being reordered within N orders\n\n# we have already counted the lenght of the streaks so if it is >= 5 then it will be added in probability.\n\ndf_with_prob_greater_5 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_5\",\n                                        F.when(F.col(\"length_of_streaks\") >= 5,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_5\").alias(\"total_streaks_greater_than_5\")\n                         )\n                         .withColumn(\"prob_of_reordered_5\",\n                             ( F.col(\"total_streaks_greater_than_5\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_5\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:50.277518Z","iopub.execute_input":"2024-10-09T12:30:50.278005Z","iopub.status.idle":"2024-10-09T12:30:50.386470Z","shell.execute_reply.started":"2024-10-09T12:30:50.277948Z","shell.execute_reply":"2024-10-09T12:30:50.385590Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 2 then it will be added in probability.\n\ndf_with_prob_greater_2 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_2\",\n                                        F.when(F.col(\"length_of_streaks\") >= 2,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_2\").alias(\"total_streaks_greater_than_2\")\n                         )\n                         .withColumn(\"prob_of_reordered_2\",\n                             ( F.col(\"total_streaks_greater_than_2\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_2\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:50.387509Z","iopub.execute_input":"2024-10-09T12:30:50.387856Z","iopub.status.idle":"2024-10-09T12:30:50.467552Z","shell.execute_reply.started":"2024-10-09T12:30:50.387818Z","shell.execute_reply":"2024-10-09T12:30:50.466275Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 3 then it will be added in probability.\n\ndf_with_prob_greater_3 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_3\",\n                                        F.when(F.col(\"length_of_streaks\") >= 3,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_3\").alias(\"total_streaks_greater_than_3\")\n                         )\n                         .withColumn(\"prob_of_reordered_3\",\n                             ( F.col(\"total_streaks_greater_than_3\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_3\")\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:50.471770Z","iopub.execute_input":"2024-10-09T12:30:50.472460Z","iopub.status.idle":"2024-10-09T12:30:50.560740Z","shell.execute_reply.started":"2024-10-09T12:30:50.472403Z","shell.execute_reply":"2024-10-09T12:30:50.559748Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"prior_orders_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:30:50.562606Z","iopub.execute_input":"2024-10-09T12:30:50.563564Z","iopub.status.idle":"2024-10-09T12:30:50.573425Z","shell.execute_reply.started":"2024-10-09T12:30:50.563402Z","shell.execute_reply":"2024-10-09T12:30:50.571501Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- user_id: integer (nullable = true)\n |-- order_number: integer (nullable = true)\n |-- order_dow: integer (nullable = true)\n |-- order_hour_of_day: integer (nullable = true)\n |-- days_since_prior_order: double (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Distribution of the day of week it is ordered\npivoted_prior_orders_df = (\n    prior_orders_df.select(\"order_id\",\"order_dow\")\n                    .groupBy(\"order_id\")\n                    .pivot(\"order_dow\")\n                    .agg(F.lit(1)).na.fill(0)\n)\n            \ndf_with_count_of_dow = (\n    prior_product_orders.select(\"order_id\",\"product_id\")\n                            .join(\n                                pivoted_prior_orders_df , on = \"order_id\",how='left'\n                            )\n                            .groupBy(\"product_id\")\n                            .agg(\n                                F.sum(\"0\").alias(\"count_of_dow_0\"),\n                                F.sum(\"1\").alias(\"count_of_dow_1\"),\n                                F.sum(\"2\").alias(\"count_of_dow_2\"),\n                                F.sum(\"3\").alias(\"count_of_dow_3\"),\n                                F.sum(\"4\").alias(\"count_of_dow_4\"),\n                                F.sum(\"5\").alias(\"count_of_dow_5\"),\n                                F.sum(\"6\").alias(\"count_of_dow_6\")\n                            )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-09T12:51:14.134038Z","iopub.execute_input":"2024-10-09T12:51:14.134543Z","iopub.status.idle":"2024-10-09T12:51:14.857727Z","shell.execute_reply.started":"2024-10-09T12:51:14.134493Z","shell.execute_reply":"2024-10-09T12:51:14.856496Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#  Probability it is reordered after the first order\ntotal_orders = prior_orders_df.select(\"order_id\").distinct().count()\n\ndf_with_prob_reord = (\n    prior_orders_df.select(\"order_id\",\"user_id\")\n                    .join(prior_product_orders.select(\"product_id\",\"order_id\"),on=\"order_id\",how='left')\n                    .groupBy(\"product_id\",\"user_id\")\n                    .agg(\n                        F.count(\"order_id\").alias(\"order_count\")\n                    )\n                    .withColumn(\"is_reordered\",\n                        F.when(F.col(\"order_count\") > 1,1).otherwise(0)\n                    )\n                    .groupBy(\"product_id\")\n                    .agg(\n                        ( \n                            (F.sum(\"is_reordered\") / total_orders).alias(\"prob_of_being_reorderd\") \n                        )\n                    )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T13:56:03.774887Z","iopub.execute_input":"2024-10-09T13:56:03.775362Z","iopub.status.idle":"2024-10-09T13:56:06.093465Z","shell.execute_reply.started":"2024-10-09T13:56:03.775319Z","shell.execute_reply":"2024-10-09T13:56:06.092137Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Statistics around the time between orders\n","metadata":{},"execution_count":null,"outputs":[]}]}