{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7487,"sourceType":"datasetVersion","datasetId":4931}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2024-10-10T07:58:37.025600Z","iopub.execute_input":"2024-10-10T07:58:37.026116Z","iopub.status.idle":"2024-10-10T07:59:41.315348Z","shell.execute_reply.started":"2024-10-10T07:58:37.026064Z","shell.execute_reply":"2024-10-10T07:59:41.313919Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=4158de655ad1021ed763038424dfcab42676c9a9b78037837400065bcadaa51c\n  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.3\nCollecting pyngrok\n  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport pyspark\nimport numpy as np\nfrom pyngrok import ngrok\nfrom pyspark.sql import SparkSession , Window\nfrom pyspark.sql import functions as F\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T07:59:41.318037Z","iopub.execute_input":"2024-10-10T07:59:41.318556Z","iopub.status.idle":"2024-10-10T07:59:41.445000Z","shell.execute_reply.started":"2024-10-10T07:59:41.318496Z","shell.execute_reply":"2024-10-10T07:59:41.443345Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create a SparkSession with custom memory settings\nspark = SparkSession.builder.appName(\"instamart_analysis\") \\\n    .config(\"spark.driver.memory\",\"25g\") \\\n    .getOrCreate()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T07:59:41.446587Z","iopub.execute_input":"2024-10-10T07:59:41.447213Z","iopub.status.idle":"2024-10-10T07:59:47.407663Z","shell.execute_reply.started":"2024-10-10T07:59:41.447170Z","shell.execute_reply":"2024-10-10T07:59:47.405723Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/10/10 07:59:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"def show_time(start):\n    return time.time() - start","metadata":{"execution":{"iopub.status.busy":"2024-10-10T07:59:47.410523Z","iopub.execute_input":"2024-10-10T07:59:47.411825Z","iopub.status.idle":"2024-10-10T07:59:47.418198Z","shell.execute_reply.started":"2024-10-10T07:59:47.411663Z","shell.execute_reply":"2024-10-10T07:59:47.416473Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"departments_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/departments.csv\")\nproducts_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/products.csv\")\nprior_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__prior.csv\").repartition(12)\ntrain_product_orders = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/order_products__train.csv\").repartition(8)\norders_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/orders.csv\").repartition(8)\naisels_df = spark.read.options(header=True,inferSchema=True).csv(\"/kaggle/input/instacart-market-basket-analysis/aisles.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T07:59:47.419579Z","iopub.execute_input":"2024-10-10T07:59:47.419990Z","iopub.status.idle":"2024-10-10T08:00:32.349730Z","shell.execute_reply.started":"2024-10-10T07:59:47.419947Z","shell.execute_reply":"2024-10-10T08:00:32.347270Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Create a tunnel to the Spark UI\nngrok.set_auth_token('2kvaYw5ZiG5bL8iM8YJBVJPk1Ru_3C16mMgmpKEBYb28PPLUe')  # Optional: set your Ngrok auth token if you have one\ntunnel = ngrok.connect(4040)\nprint(\"Ngrok tunnel \\\"{}\\\" -> \\\"http://localhost:4040\\\"\".format(tunnel.public_url))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:32.351688Z","iopub.execute_input":"2024-10-10T08:00:32.352872Z","iopub.status.idle":"2024-10-10T08:00:34.536363Z","shell.execute_reply.started":"2024-10-10T08:00:32.352808Z","shell.execute_reply":"2024-10-10T08:00:34.535095Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Ngrok tunnel \"https://9eb6-35-204-191-123.ngrok-free.app\" -> \"http://localhost:4040\"                \n","output_type":"stream"}]},{"cell_type":"code","source":"prior_product_orders.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:34.537638Z","iopub.execute_input":"2024-10-10T08:00:34.538011Z","iopub.status.idle":"2024-10-10T08:00:34.547448Z","shell.execute_reply.started":"2024-10-10T08:00:34.537973Z","shell.execute_reply":"2024-10-10T08:00:34.545997Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- product_id: integer (nullable = true)\n |-- add_to_cart_order: integer (nullable = true)\n |-- reordered: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:34.548626Z","iopub.execute_input":"2024-10-10T08:00:34.549273Z","iopub.status.idle":"2024-10-10T08:00:34.561750Z","shell.execute_reply.started":"2024-10-10T08:00:34.549211Z","shell.execute_reply":"2024-10-10T08:00:34.560457Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"root\n |-- order_id: integer (nullable = true)\n |-- user_id: integer (nullable = true)\n |-- eval_set: string (nullable = true)\n |-- order_number: integer (nullable = true)\n |-- order_dow: integer (nullable = true)\n |-- order_hour_of_day: integer (nullable = true)\n |-- days_since_prior_order: double (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"orders_df.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:34.564085Z","iopub.execute_input":"2024-10-10T08:00:34.564564Z","iopub.status.idle":"2024-10-10T08:00:34.729087Z","shell.execute_reply.started":"2024-10-10T08:00:34.564519Z","shell.execute_reply":"2024-10-10T08:00:34.727741Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, user_id: int, eval_set: string, order_number: int, order_dow: int, order_hour_of_day: int, days_since_prior_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"train_orders_df = orders_df.filter(orders_df[\"eval_set\"] =='train').drop(\"eval_set\")\nprior_orders_df = orders_df.filter(orders_df[\"eval_set\"] == 'prior').drop(\"eval_set\")\ntrain_orders_df.cache()\ntrain_product_orders.cache()\nprior_orders_df.cache()\nprior_product_orders.cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:34.734866Z","iopub.execute_input":"2024-10-10T08:00:34.735285Z","iopub.status.idle":"2024-10-10T08:00:34.937189Z","shell.execute_reply.started":"2024-10-10T08:00:34.735245Z","shell.execute_reply":"2024-10-10T08:00:34.936023Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, product_id: int, add_to_cart_order: int, reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often user has reorderd\nprior_product_orders.select(\"reordered\",\"order_id\").join(\n        prior_orders_df.select(\"user_id\",\"order_id\"),how=\"left\",on=\"order_id\"\n    ).select(\"user_id\",\"reordered\") \\\n     .groupBy(\"user_id\").agg(\n            F.count(F.col(\"reordered\")).alias(\"frequency of reorder\")\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:34.938693Z","iopub.execute_input":"2024-10-10T08:00:34.939844Z","iopub.status.idle":"2024-10-10T08:00:35.136579Z","shell.execute_reply.started":"2024-10-10T08:00:34.939783Z","shell.execute_reply":"2024-10-10T08:00:35.135495Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, frequency of reorder: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# time since privious order\nprior_orders_df.select(\"user_id\",\"days_since_prior_order\",\"order_hour_of_day\",\"order_number\",\"order_id\") \\\n                .withColumn(\"privious_order_hour\",\n                            F.lag(\"order_hour_of_day\",1) \\\n                            .over(Window.partitionBy(\"user_id\").orderBy(\"order_number\"))) \\\n                .withColumn(\"time_since_Last_order\",\n                            F.col(\"days_since_prior_order\") * 24 + \n                            F.col(\"order_hour_of_day\") - \n                            F.col(\"privious_order_hour\") \n                           ) \\\n                .select(\"order_id\",\"time_since_last_order\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:35.138588Z","iopub.execute_input":"2024-10-10T08:00:35.139159Z","iopub.status.idle":"2024-10-10T08:00:35.336200Z","shell.execute_reply.started":"2024-10-10T08:00:35.139100Z","shell.execute_reply":"2024-10-10T08:00:35.335052Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataFrame[order_id: int, time_since_last_order: double]"},"metadata":{}}]},{"cell_type":"code","source":"#time of the day user visits\nprior_orders_df.select(\"user_id\" , \"order_hour_of_day\",\"order_id\") \\\n                .groupBy(\"user_id\",\"order_hour_of_day\") \\\n                .agg(F.count(\"order_id\").alias(\"frequency\")) \\\n                .groupBy(\"user_id\") \\\n                .agg(F.max(\"frequency\").alias(\"maximum_frquency\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:35.337668Z","iopub.execute_input":"2024-10-10T08:00:35.338472Z","iopub.status.idle":"2024-10-10T08:00:35.430076Z","shell.execute_reply.started":"2024-10-10T08:00:35.338416Z","shell.execute_reply":"2024-10-10T08:00:35.428875Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, maximum_frquency: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# does the user have ordered asian , gluten free, or organic item \nprior_product_orders.select(\"order_id\",\"product_id\") \\\n            .join(products_df.select(\"product_id\",\"product_name\"), on=\"product_id\", how='left') \\\n            .join(prior_orders_df.select(\"user_id\",\"order_id\"), on=\"order_id\", how='left') \\\n            .groupBy(\"user_id\", \"order_id\") \\\n            .agg(F.collect_list(\"product_name\").alias(\"list_of_products\")) \\\n            .withColumn(\"normalized_list\", F.expr(\"transform(list_of_products, x -> lower(x))\")) \\\n            .withColumn(\"contains_or_not\", \n                F.expr(\"exists(normalized_list,x -> x like '%organic%')\")\n              | F.expr(\"exists(normalized_list, x -> x like '%asian%')\")\n              | F.expr(\"exists(normalized_list, x-> x like '%gluten free%')\")\n            ) \\\n            .filter(F.col(\"contains_or_not\") == True) \\\n            .select(\"user_id\", \"order_id\") ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-10T08:00:35.457222Z","iopub.execute_input":"2024-10-10T08:00:35.458138Z","iopub.status.idle":"2024-10-10T08:00:35.906661Z","shell.execute_reply.started":"2024-10-10T08:00:35.458078Z","shell.execute_reply":"2024-10-10T08:00:35.905435Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, order_id: int]"},"metadata":{}}]},{"cell_type":"code","source":"# feature based on order size \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\") , on=\"order_id\", how=\"left\") \\\n                    .groupBy(\"user_id\",'order_id') \\\n                    .agg(\n                            F.count(F.col(\"product_id\")).alias(\"count_of_product\")\n                        ) \\\n                    .groupBy(\"user_id\") \\\n                    .agg(\n                            F.max(F.col(\"count_of_product\")).alias(\"max_count_of_products\"),\n                            F.min(F.col(\"count_of_product\")).alias(\"min_count_of_products\"),\n                            F.mean(F.col(\"count_of_product\")).alias(\"mean_count_of_products\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:35.912381Z","iopub.execute_input":"2024-10-10T08:00:35.913393Z","iopub.status.idle":"2024-10-10T08:00:36.065324Z","shell.execute_reply.started":"2024-10-10T08:00:35.913264Z","shell.execute_reply":"2024-10-10T08:00:36.063989Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, max_count_of_products: bigint, min_count_of_products: bigint, mean_count_of_products: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many of the user’s orders contained no previously purchased items\nprior_product_orders.select(\"order_id\",\"reordered\") \\\n                    .join(prior_orders_df.select(\"order_id\",\"user_id\") , on = 'order_id' , how = 'left') \\\n                    .groupBy(\"user_Id\",\"order_id\") \\\n                    .agg(\n                            F.collect_list(F.col(\"reordered\")).alias(\"reordered_array\")\n                        ) \\\n                    .withColumn(\"doesnt_contains_reordered\" ,\n                            F.when(F.array_contains(\"reordered_array\",1),0).otherwise(1)\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.072005Z","iopub.execute_input":"2024-10-10T08:00:36.072623Z","iopub.status.idle":"2024-10-10T08:00:36.209192Z","shell.execute_reply.started":"2024-10-10T08:00:36.072563Z","shell.execute_reply":"2024-10-10T08:00:36.207882Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_Id: int, order_id: int, reordered_array: array<int>, doesnt_contains_reordered: int]"},"metadata":{}}]},{"cell_type":"code","source":"# how often the item has purchaced \nprior_product_orders.select(\"product_id\",\"order_id\") \\\n                     .groupBy(\"product_id\") \\\n                     .agg(\n                             F.count(F.col(\"order_id\")).alias(\"product_count\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.210413Z","iopub.execute_input":"2024-10-10T08:00:36.210879Z","iopub.status.idle":"2024-10-10T08:00:36.263487Z","shell.execute_reply.started":"2024-10-10T08:00:36.210826Z","shell.execute_reply":"2024-10-10T08:00:36.262218Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_count: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# position of product \nprior_product_orders.select(\"product_id\",\"add_to_cart_order\") \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.mean(F.col(\"add_to_cart_order\")).alias(\"product_mean_of_position\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.265486Z","iopub.execute_input":"2024-10-10T08:00:36.266019Z","iopub.status.idle":"2024-10-10T08:00:36.320163Z","shell.execute_reply.started":"2024-10-10T08:00:36.265963Z","shell.execute_reply":"2024-10-10T08:00:36.318910Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, product_mean_of_position: double]"},"metadata":{}}]},{"cell_type":"code","source":"# How many users buy it as \"one shot\" item\nprior_product_orders.select(\"order_id\",\"product_id\") \\\n                    .groupBy(\"order_id\") \\\n                    .agg(F.collect_list(\"product_id\").alias(\"list_of_products\")) \\\n                    .withColumn(\"is_one_shot_order\",\n                                   F.when(F.size(F.col(\"list_of_products\")) == 1,1).otherwise(0)\n                               ) \\\n                    .withColumn(\"product_id\",F.explode(F.col(\"list_of_products\"))) \\\n                    .join(prior_orders_df.select(\"user_id\",\"order_id\"),on=\"order_id\",how='left') \\\n                    .groupBy(\"product_id\",\"user_id\") \\\n                    .agg(F.collect_list(F.col(\"is_one_shot_order\")).alias(\"is_one_shot_order_list\")) \\\n                    .withColumn(\"has_user_purchased_one_shot\",F.when(F.array_contains(\"is_one_shot_order_list\",1),1).otherwise(0)) \\\n                    .groupBy(\"product_id\") \\\n                    .agg(\n                            F.sum(F.col(\"has_user_purchased_one_shot\")).alias(\"number_of_user_purchased_item\")\n                        ) ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.322130Z","iopub.execute_input":"2024-10-10T08:00:36.322632Z","iopub.status.idle":"2024-10-10T08:00:36.525230Z","shell.execute_reply.started":"2024-10-10T08:00:36.322577Z","shell.execute_reply":"2024-10-10T08:00:36.524051Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DataFrame[product_id: int, number_of_user_purchased_item: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# Stats on the number of items that co-occur with this item\n\n# 1. number of time that a item has co occured.\n\n# Perform a self-join on prior_product_orders\nresult_df = (\n    prior_product_orders\n    .select(\"product_id\", \"order_id\")\n    .alias(\"df1\")\n    .join(\n        prior_product_orders.select(\"product_id\", \"order_id\")\n        .withColumnRenamed(\"product_id\", \"product_id_1\")\n        .alias(\"df2\"),\n        (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n        \"left\"\n    )\n    .groupBy(\"df1.product_id\")\n    .agg(F.count(F.col(\"df2.product_id_1\")).alias(\"number_of_product_co_occurred\"))\n)\n\n# 2 average number of items that is co ocuured with this item in single order\n\nresult_df = (\n                prior_product_orders.select(\"product_id\",\"order_id\").alias(\"ppo1\") \n                .join(\n                    prior_product_orders.select(\"product_id\",\"order_id\")\n                    .alias(\"ppo2\"),\n                    (F.col(\"ppo1.order_id\") == F.col(\"ppo2.order_id\")) & \n                    (F.col(\"ppo1.product_id\") != F.col(\"ppo2.product_id\")),\n                    how='left'\n                ) \n                .groupBy(\"ppo1.product_id\",\"ppo1.order_id\")\n                .agg(F.count(F.col(\"ppo2.product_id\")).alias(\"count_of_co_ocuured_product_per_order\"))\n                .groupBy(\"ppo1.product_id\")\n                .agg(\n                    F.mean(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"mean_of_co_ocuured_product_per_order\"),\n                    F.min(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"min_of_co_ocuured_product_per_order\"),\n                    F.max(F.col(\"count_of_co_ocuured_product_per_order\")).alias(\"max_of_co_ocuured_product_per_order\"),\n\n                )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.526711Z","iopub.execute_input":"2024-10-10T08:00:36.527127Z","iopub.status.idle":"2024-10-10T08:00:36.793642Z","shell.execute_reply.started":"2024-10-10T08:00:36.527083Z","shell.execute_reply":"2024-10-10T08:00:36.792492Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Stats on the order streak\n\n# 1. let's add the flag whether streak is continued or not\ndf_with_flag= (\n\n    prior_product_orders.select(\"product_id\",\"order_id\")\n                        .join(\n                                prior_orders_df.select(\"user_id\",\"order_number\",\"order_id\"),\n                                how ='left',\n                                on = 'order_id' \n                            )\n                        .withColumn(\"next_order_number\",\n                            F.lead(F.col(\"order_number\"),1).over(Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\"))\n                        )\n                        .withColumn(\"is_streak_continued_flag\",\n                               F.when(F.col(\"next_order_number\") - F.col(\"order_number\") == 1,1)\n                                    .otherwise(0)\n                            )\n)\n# 2. let's assign an unique id to each streak of a perticular user and product.\n\nw1 = Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\")\nw2 = Window.partitionBy(\"user_id\",\"product_id\",\"is_streak_continued_flag\").orderBy(\"order_number\")\n\n# by using the above window we can create unique id for streak named grp then can find streak leangth.\ndf_with_streak_length = (\n    df_with_flag.withColumn(\"grp\",F.row_number().over(w1) - F.row_number().over(w2))\n                .groupBy(\"user_id\",\"product_id\",\"grp\")\n                .agg(\n                    F.count(\"order_number\").alias(\"length_of_streaks\")\n                )\n)\n\n# finally , summarize it over each prodcut rather than per user per product.\ndf_with_stats_of_streaks = (\n    df_with_streak_length.select(\"product_id\",\"length_of_streaks\",\"grp\")\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count('grp').alias(\"Total_streak_of_this_product\"),\n                             F.mean(\"length_of_streaks\").alias(\"mean_of_streaks_of_this_product\"),\n                             F.min(\"length_of_streaks\").alias(\"max_of_streaks_of_this_product\"),\n                             F.max(\"length_of_streaks\").alias(\"min_of_streaks_of_this_product\")\n                         \n                         )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:36.796859Z","iopub.execute_input":"2024-10-10T08:00:36.797443Z","iopub.status.idle":"2024-10-10T08:00:37.070565Z","shell.execute_reply.started":"2024-10-10T08:00:36.797380Z","shell.execute_reply":"2024-10-10T08:00:37.069254Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Probability of being reordered within N orders\n\n# we have already counted the lenght of the streaks so if it is >= 5 then it will be added in probability.\n\ndf_with_prob_greater_5 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_5\",\n                                        F.when(F.col(\"length_of_streaks\") >= 5,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_5\").alias(\"total_streaks_greater_than_5\")\n                         )\n                         .withColumn(\"prob_of_reordered_5\",\n                             ( F.col(\"total_streaks_greater_than_5\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_5\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:37.072147Z","iopub.execute_input":"2024-10-10T08:00:37.073051Z","iopub.status.idle":"2024-10-10T08:00:37.173892Z","shell.execute_reply.started":"2024-10-10T08:00:37.072993Z","shell.execute_reply":"2024-10-10T08:00:37.172976Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 2 then it will be added in probability.\n\ndf_with_prob_greater_2 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_2\",\n                                        F.when(F.col(\"length_of_streaks\") >= 2,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_2\").alias(\"total_streaks_greater_than_2\")\n                         )\n                         .withColumn(\"prob_of_reordered_2\",\n                             ( F.col(\"total_streaks_greater_than_2\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_2\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:37.176722Z","iopub.execute_input":"2024-10-10T08:00:37.177627Z","iopub.status.idle":"2024-10-10T08:00:37.256432Z","shell.execute_reply.started":"2024-10-10T08:00:37.177569Z","shell.execute_reply":"2024-10-10T08:00:37.255206Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# we have already counted the lenght of the streaks so if it is >= 3 then it will be added in probability.\n\ndf_with_prob_greater_3 = (\n    df_with_streak_length.withColumn(\"is_streak_length_greater_than_3\",\n                                        F.when(F.col(\"length_of_streaks\") >= 3,1).otherwise(0) \n                                    )\n                         .groupBy(\"product_id\")\n                         .agg(\n                             F.count(\"length_of_streaks\").alias(\"total_streaks\"),\n                             F.sum(\"is_streak_length_greater_than_3\").alias(\"total_streaks_greater_than_3\")\n                         )\n                         .withColumn(\"prob_of_reordered_3\",\n                             ( F.col(\"total_streaks_greater_than_3\") / F.col(\"total_streaks\"))\n                         )\n                         .select(\"product_id\",\"prob_of_reordered_3\")\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:37.260731Z","iopub.execute_input":"2024-10-10T08:00:37.262204Z","iopub.status.idle":"2024-10-10T08:00:37.343809Z","shell.execute_reply.started":"2024-10-10T08:00:37.262140Z","shell.execute_reply":"2024-10-10T08:00:37.342138Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Distribution of the day of week it is ordered\npivoted_prior_orders_df = (\n    prior_orders_df.select(\"order_id\",\"order_dow\")\n                    .groupBy(\"order_id\")\n                    .pivot(\"order_dow\")\n                    .agg(F.lit(1)).na.fill(0)\n)\n            \ndf_with_count_of_dow = (\n    prior_product_orders.select(\"order_id\",\"product_id\")\n                            .join(\n                                pivoted_prior_orders_df , on = \"order_id\",how='left'\n                            )\n                            .groupBy(\"product_id\")\n                            .agg(\n                                F.sum(\"0\").alias(\"count_of_dow_0\"),\n                                F.sum(\"1\").alias(\"count_of_dow_1\"),\n                                F.sum(\"2\").alias(\"count_of_dow_2\"),\n                                F.sum(\"3\").alias(\"count_of_dow_3\"),\n                                F.sum(\"4\").alias(\"count_of_dow_4\"),\n                                F.sum(\"5\").alias(\"count_of_dow_5\"),\n                                F.sum(\"6\").alias(\"count_of_dow_6\")\n                            )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:37.362910Z","iopub.execute_input":"2024-10-10T08:00:37.363961Z","iopub.status.idle":"2024-10-10T08:00:59.256656Z","shell.execute_reply.started":"2024-10-10T08:00:37.363898Z","shell.execute_reply":"2024-10-10T08:00:59.254621Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#  Probability it is reordered after the first order\ntotal_orders = prior_orders_df.select(\"order_id\").distinct().count()\n\ndf_with_prob_reord = (\n    prior_orders_df.select(\"order_id\",\"user_id\")\n                    .join(prior_product_orders.select(\"product_id\",\"order_id\"),on=\"order_id\",how='left')\n                    .groupBy(\"product_id\",\"user_id\")\n                    .agg(\n                        F.count(\"order_id\").alias(\"order_count\")\n                    )\n                    .groupBy(\"product_id\")\n                    .agg(\n                        ( \n                            (F.sum(\"order_count\") / total_orders).alias(\"prob_of_being_reordered\") \n                        )\n                    )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:00:59.259009Z","iopub.execute_input":"2024-10-10T08:00:59.259924Z","iopub.status.idle":"2024-10-10T08:01:03.995664Z","shell.execute_reply.started":"2024-10-10T08:00:59.259860Z","shell.execute_reply":"2024-10-10T08:01:03.993950Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Number of orders in which the user purchases the item\n\ndf_with_num_of_order_p_product = (\n    \n    prior_product_orders.select(\"order_id\",\"product_id\")\n                        .join(\n                            prior_orders_df.select(\"order_id\",\"user_id\")\n                            , how = 'left' , on = 'order_id'\n                        )\n                        .groupBy(\"user_id\",\"product_id\")\n                        .agg(\n                            F.count(\"order_id\").alias(\"num_of_ord_purch_p_prod\")\n                        )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:03:45.102255Z","iopub.execute_input":"2024-10-10T08:03:45.102728Z","iopub.status.idle":"2024-10-10T08:03:45.166243Z","shell.execute_reply.started":"2024-10-10T08:03:45.102660Z","shell.execute_reply":"2024-10-10T08:03:45.164655Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# # Days since the user last purchased the item\n\n# w1 = Window.partitionBy(\"user_id\",\"product_id\").orderBy(\"order_number\")\n# df_with_next_order_p_prod = (\n#     prior_product_orders.select(\"product_id\",\"order_id\")\n#                         .join(\n#                             prior_orders_df.select(\"user_id\",\"order_id\",\"order_number\",\"days_since_prior_order\")\n#                                             .groupBy(\"user_id\")\n#                                             .agg(\n#                                                 F.collect_list(\"days_since_prior_order\").alias(\"list_of_days_since_prior_ord\"),\n#                                                 F.collect_list(\"order_number\").alias(\"list_of_order_number\")\n#                                             )\n#                             ,\n#                             how='left',on='order_id'\n#                         )\n#                         .withColumn(\"pre_order_number\",\n#                             F.lag(F.col(\"order_number\")).over(w1)\n                                \n#                         ).na.fill({'pre_order_number':0})\n#                         .sort(\"user_id\",\"product_id\",\"order_number\")\n#                         .show()\n                        \n# )\n\n# w2 = Window.partitionBy(\"user_id\").orderBy(\"order_number\") \\\n#                         .rowsBetween(\n#                             F.when(F.col(\"pre_order_number\") == 0,Window.unboundedPreceding).otherwise(F.col(\"pre_order_number\")) ,\n#                             F.col(\"order_number\")\n#                         )\n\n# df_with_days_since_last_ord_p_prod = (\n#     df_with_next_order_p_prod.join(\n#                                 prior_orders_df.select(\"user_id\",\"days_since_prior_orders\"),\n#                                 how='left',on='user_id'\n#                             ).sort(\"user_id\",\"order\")\n#                             .groupBy(\"user_id\")\n#                             .withColum(\"sum_day_since_last_order\",\n#                                 F.sum(\"days_since_prior_order\").over(w2)\n#                             )\n# )","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:18:54.624000Z","iopub.execute_input":"2024-10-10T08:18:54.624529Z","iopub.status.idle":"2024-10-10T08:18:54.632028Z","shell.execute_reply.started":"2024-10-10T08:18:54.624483Z","shell.execute_reply":"2024-10-10T08:18:54.630750Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Streak (number of orders in a row the user has purchased the item)\ndf_with_streak_length","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:20:54.102966Z","iopub.execute_input":"2024-10-10T08:20:54.103437Z","iopub.status.idle":"2024-10-10T08:20:54.113518Z","shell.execute_reply.started":"2024-10-10T08:20:54.103393Z","shell.execute_reply":"2024-10-10T08:20:54.112333Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DataFrame[user_id: int, product_id: int, grp: int, length_of_streaks: bigint]"},"metadata":{}}]},{"cell_type":"code","source":"# Position in the cart\ndf_with_position_cart_p_usr_p_prod = (\n    prior_product_orders.select(\"product_id\",\"add_to_cart_order\",\"order_id\") \n                    .join(\n                        prior_orders_df.select(\"user_id\",\"order_id\"),\n                        how = 'left' , on = 'order_id'\n                    )\n                    .groupBy(\"user_id\",\"product_id\") \n                    .agg(\n                            F.mean(F.col(\"add_to_cart_order\")).alias(\"prod_mean_of_position_p_user\")\n                        )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:26:25.303568Z","iopub.execute_input":"2024-10-10T08:26:25.304883Z","iopub.status.idle":"2024-10-10T08:26:59.923031Z","shell.execute_reply.started":"2024-10-10T08:26:25.304827Z","shell.execute_reply":"2024-10-10T08:26:59.921840Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"[Stage 81:>                                                         (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+-------+----------+----------------------------+\n|user_id|product_id|prod_mean_of_position_p_user|\n+-------+----------+----------------------------+\n| 152610|     11175|                        11.5|\n|   4076|     47049|                        11.0|\n|  41502|     29487|           5.333333333333333|\n| 179433|      8174|                        23.0|\n| 147552|      2611|                        13.0|\n|  37763|      9755|                         7.0|\n|  70318|     49112|           4.333333333333333|\n| 184695|      4462|                        14.0|\n| 201623|     10017|           8.548387096774194|\n|  21237|     35535|                         8.5|\n|  19259|     44085|          4.3076923076923075|\n|  12016|     47006|                         3.0|\n|  51227|     32369|                        11.7|\n| 198165|     48043|          3.0869565217391304|\n|  18244|     43735|                         2.0|\n| 205943|     24852|                       3.375|\n| 192552|      7644|                         9.0|\n|  63226|     36550|           4.666666666666667|\n|  17224|     43352|            9.88888888888889|\n|  94710|     31506|                         7.6|\n+-------+----------+----------------------------+\nonly showing top 20 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Co-occurrence statistics\n\ndf_with_co_ocrd_stats_p_user_p_prod = (\n    prior_product_orders\n    .select(\"product_id\", \"order_id\")\n    .alias(\"df1\")\n    .join(prior_orders_df.select(\"user_id\",\"order_id\"),\n         on = 'order_id',how='left'\n         )\n    .join(\n        prior_product_orders.select(\"product_id\", \"order_id\")\n        .withColumnRenamed(\"product_id\", \"product_id_1\")\n        .alias(\"df2\"),\n        (F.col(\"df1.order_id\") == F.col(\"df2.order_id\")) & (F.col(\"df1.product_id\") != F.col(\"df2.product_id_1\")),\n        \"left\"\n    )\n    .groupBy(\"user_id\",\"df1.product_id\")\n    .agg(\n        F.count(F.col(\"df2.product_id_1\")).alias(\"num_of_prod_co_ocrd_p_usr_p_prod\"),\n    )\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:44:59.038323Z","iopub.execute_input":"2024-10-10T08:44:59.039095Z","iopub.status.idle":"2024-10-10T08:44:59.149058Z","shell.execute_reply.started":"2024-10-10T08:44:59.039029Z","shell.execute_reply":"2024-10-10T08:44:59.147861Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#     Counts by day of wee\ndf_with_count_of_dow = (\n        prior_orders_df.select(\"order_id\",\"order_dow\")\n                        .groupBy(\"order_id\")\n                        .pivot(\"order_dow\")\n                        .agg(F.lit(1))\n                        .na.fill(0)\n                        .agg(*\n                              [\n                                F.sum(f\"{i}\").alias(f\"count_dow_{i}\") for i in range(7)\n                                ]\n                            )\n)\n\n#     Counts by hour\ndf_with_count_of_ohod = (\n        prior_orders_df.select(\"order_id\",\"order_hour_of_day\")\n                        .groupBy(\"order_id\")\n                        .pivot(\"order_hour_of_day\")\n                        .agg(F.lit(1))\n                        .na.fill(0)\n                        .agg(*\n                              [\n                                F.sum(f\"{i}\").alias(f\"count_ohod_{i}\") for i in range(24)\n                                ]\n                            )\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T09:12:48.447415Z","iopub.execute_input":"2024-10-10T09:12:48.448079Z","iopub.status.idle":"2024-10-10T09:12:49.796474Z","shell.execute_reply.started":"2024-10-10T09:12:48.448019Z","shell.execute_reply":"2024-10-10T09:12:49.795048Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}